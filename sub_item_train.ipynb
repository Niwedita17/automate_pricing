{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_code</th>\n",
       "      <th>material</th>\n",
       "      <th>box_code</th>\n",
       "      <th>bursting_factor</th>\n",
       "      <th>flute_type</th>\n",
       "      <th>inner_height_mm</th>\n",
       "      <th>height_inch</th>\n",
       "      <th>inner_height</th>\n",
       "      <th>length_inch</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>quantity</th>\n",
       "      <th>status</th>\n",
       "      <th>company_id</th>\n",
       "      <th>per_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BZ-SKU-0000027</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"PC1\"</td>\n",
       "      <td>\"24x22x22x22x22\"</td>\n",
       "      <td>\"BB\"</td>\n",
       "      <td>\"646\"</td>\n",
       "      <td>\"3.9\"</td>\n",
       "      <td>\"687\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>795</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>6.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BZ-SKU-0000027</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"PC1\"</td>\n",
       "      <td>\"24x22x22x22x22\"</td>\n",
       "      <td>\"BB\"</td>\n",
       "      <td>\"646\"</td>\n",
       "      <td>\"3.9\"</td>\n",
       "      <td>\"687\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>12490</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BZ-SKU-0004768</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"Regular 5P34\"</td>\n",
       "      <td>\"20x18x18x18x18\"</td>\n",
       "      <td>\"BC\"</td>\n",
       "      <td>\"300\"</td>\n",
       "      <td>\"11.8\"</td>\n",
       "      <td>\"730\"</td>\n",
       "      <td>\"28.7\"</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>63.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BZ-SKU-0005542</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"5P34.2 Regular (3)\"</td>\n",
       "      <td>\"20x18x18x18x18\"</td>\n",
       "      <td>\"BC\"</td>\n",
       "      <td>\"300\"</td>\n",
       "      <td>\"11.8\"</td>\n",
       "      <td>\"730\"</td>\n",
       "      <td>\"28.7\"</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>2165</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BZ-SKU-0005542</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"5P34.2 Regular (3)\"</td>\n",
       "      <td>\"20x18x18x18x18\"</td>\n",
       "      <td>\"BC\"</td>\n",
       "      <td>\"300\"</td>\n",
       "      <td>\"11.8\"</td>\n",
       "      <td>\"730\"</td>\n",
       "      <td>\"28.7\"</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>315</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BZ-SKU-0004768</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"Regular 5P34\"</td>\n",
       "      <td>\"20x18x18x18x18\"</td>\n",
       "      <td>\"BC\"</td>\n",
       "      <td>\"300\"</td>\n",
       "      <td>\"11.8\"</td>\n",
       "      <td>\"730\"</td>\n",
       "      <td>\"28.7\"</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>825</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>67.229947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BZ-SKU-0000068</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A1\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"101.14\"</td>\n",
       "      <td>\"4.1\"</td>\n",
       "      <td>\"306.88\"</td>\n",
       "      <td>\"12.2\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>4606</td>\n",
       "      <td>6.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BZ-SKU-0000068</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A1\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"101.14\"</td>\n",
       "      <td>\"4.1\"</td>\n",
       "      <td>\"306.88\"</td>\n",
       "      <td>\"12.2\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1998</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BZ-SKU-0000068</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A1\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"101.14\"</td>\n",
       "      <td>\"4.1\"</td>\n",
       "      <td>\"306.88\"</td>\n",
       "      <td>\"12.2\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>6.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BZ-SKU-0000068</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A1\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"101.14\"</td>\n",
       "      <td>\"4.1\"</td>\n",
       "      <td>\"306.88\"</td>\n",
       "      <td>\"12.2\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BZ-SKU-0000068</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A1\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"101.14\"</td>\n",
       "      <td>\"4.1\"</td>\n",
       "      <td>\"306.88\"</td>\n",
       "      <td>\"12.2\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BZ-SKU-0000068</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A1\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"101.14\"</td>\n",
       "      <td>\"4.1\"</td>\n",
       "      <td>\"306.88\"</td>\n",
       "      <td>\"12.2\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>990</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BZ-SKU-0000068</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A1\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"101.14\"</td>\n",
       "      <td>\"4.1\"</td>\n",
       "      <td>\"306.88\"</td>\n",
       "      <td>\"12.2\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BZ-SKU-0000058</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A5\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90.98\"</td>\n",
       "      <td>\"3.7\"</td>\n",
       "      <td>\"197.66\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BZ-SKU-0000058</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A5\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90.98\"</td>\n",
       "      <td>\"3.7\"</td>\n",
       "      <td>\"197.66\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>5.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BZ-SKU-0000058</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A5\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90.98\"</td>\n",
       "      <td>\"3.7\"</td>\n",
       "      <td>\"197.66\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BZ-SKU-0000058</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A5\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90.98\"</td>\n",
       "      <td>\"3.7\"</td>\n",
       "      <td>\"197.66\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>5.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BZ-SKU-0000058</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A5\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90.98\"</td>\n",
       "      <td>\"3.7\"</td>\n",
       "      <td>\"197.66\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BZ-SKU-0000058</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A5\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90.98\"</td>\n",
       "      <td>\"3.7\"</td>\n",
       "      <td>\"197.66\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>5.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BZ-SKU-0000058</td>\n",
       "      <td>\"Paper\"</td>\n",
       "      <td>\"A5\"</td>\n",
       "      <td>\"22x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90.98\"</td>\n",
       "      <td>\"3.7\"</td>\n",
       "      <td>\"197.66\"</td>\n",
       "      <td>\"7.9\"</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BZ-SKU-0000029</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"CB1\"</td>\n",
       "      <td>\"24x22x22\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"80\"</td>\n",
       "      <td>\"3.1\"</td>\n",
       "      <td>\"660\"</td>\n",
       "      <td>\"26\"</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>41.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>13000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>28925</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>755</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>4.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>4.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>26174</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>28550</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>4.639527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BZ-SKU-0000394</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box2\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"90\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>\"220\"</td>\n",
       "      <td>\"8\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>2950</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>3.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>2800</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>7.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>3040</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>7.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>10000</td>\n",
       "      <td>8</td>\n",
       "      <td>7746</td>\n",
       "      <td>7.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>7.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7746</td>\n",
       "      <td>7.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>5000</td>\n",
       "      <td>7</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>44975</td>\n",
       "      <td>3</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>7.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>11000</td>\n",
       "      <td>1</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>15000</td>\n",
       "      <td>4</td>\n",
       "      <td>9508</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>9508</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>7746</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>9700</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>BZ-SKU-0000084</td>\n",
       "      <td>\"Top paper golden Kraft rest brown Kraft\"</td>\n",
       "      <td>\"FirstCry Box3A\"</td>\n",
       "      <td>\"24x20x20\"</td>\n",
       "      <td>\"B\"</td>\n",
       "      <td>\"120\"</td>\n",
       "      <td>\"4\"</td>\n",
       "      <td>\"250\"</td>\n",
       "      <td>\"9\"</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>9508</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sku_code                                   material  \\\n",
       "0    BZ-SKU-0000027  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "1    BZ-SKU-0000027  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "2    BZ-SKU-0004768                                    \"Paper\"   \n",
       "3    BZ-SKU-0005542                                    \"Paper\"   \n",
       "4    BZ-SKU-0005542                                    \"Paper\"   \n",
       "5    BZ-SKU-0004768                                    \"Paper\"   \n",
       "6    BZ-SKU-0000068                                    \"Paper\"   \n",
       "7    BZ-SKU-0000068                                    \"Paper\"   \n",
       "8    BZ-SKU-0000068                                    \"Paper\"   \n",
       "9    BZ-SKU-0000068                                    \"Paper\"   \n",
       "10   BZ-SKU-0000068                                    \"Paper\"   \n",
       "11   BZ-SKU-0000068                                    \"Paper\"   \n",
       "12   BZ-SKU-0000068                                    \"Paper\"   \n",
       "13   BZ-SKU-0000058                                    \"Paper\"   \n",
       "14   BZ-SKU-0000058                                    \"Paper\"   \n",
       "15   BZ-SKU-0000058                                    \"Paper\"   \n",
       "16   BZ-SKU-0000058                                    \"Paper\"   \n",
       "17   BZ-SKU-0000058                                    \"Paper\"   \n",
       "18   BZ-SKU-0000058                                    \"Paper\"   \n",
       "19   BZ-SKU-0000058                                    \"Paper\"   \n",
       "20   BZ-SKU-0000029  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "21   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "22   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "23   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "24   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "25   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "26   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "27   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "28   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "29   BZ-SKU-0000394  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "..              ...                                        ...   \n",
       "864  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "865  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "866  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "867  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "868  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "869  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "870  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "871  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "872  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "873  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "874  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "875  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "876  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "877  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "878  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "879  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "880  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "881  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "882  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "883  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "884  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "885  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "886  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "887  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "888  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "889  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "890  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "891  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "892  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "893  BZ-SKU-0000084  \"Top paper golden Kraft rest brown Kraft\"   \n",
       "\n",
       "                 box_code   bursting_factor flute_type inner_height_mm  \\\n",
       "0                   \"PC1\"  \"24x22x22x22x22\"       \"BB\"           \"646\"   \n",
       "1                   \"PC1\"  \"24x22x22x22x22\"       \"BB\"           \"646\"   \n",
       "2          \"Regular 5P34\"  \"20x18x18x18x18\"       \"BC\"           \"300\"   \n",
       "3    \"5P34.2 Regular (3)\"  \"20x18x18x18x18\"       \"BC\"           \"300\"   \n",
       "4    \"5P34.2 Regular (3)\"  \"20x18x18x18x18\"       \"BC\"           \"300\"   \n",
       "5          \"Regular 5P34\"  \"20x18x18x18x18\"       \"BC\"           \"300\"   \n",
       "6                    \"A1\"        \"22x22x22\"        \"B\"        \"101.14\"   \n",
       "7                    \"A1\"        \"22x22x22\"        \"B\"        \"101.14\"   \n",
       "8                    \"A1\"        \"22x22x22\"        \"B\"        \"101.14\"   \n",
       "9                    \"A1\"        \"22x22x22\"        \"B\"        \"101.14\"   \n",
       "10                   \"A1\"        \"22x22x22\"        \"B\"        \"101.14\"   \n",
       "11                   \"A1\"        \"22x22x22\"        \"B\"        \"101.14\"   \n",
       "12                   \"A1\"        \"22x22x22\"        \"B\"        \"101.14\"   \n",
       "13                   \"A5\"        \"22x22x22\"        \"B\"         \"90.98\"   \n",
       "14                   \"A5\"        \"22x22x22\"        \"B\"         \"90.98\"   \n",
       "15                   \"A5\"        \"22x22x22\"        \"B\"         \"90.98\"   \n",
       "16                   \"A5\"        \"22x22x22\"        \"B\"         \"90.98\"   \n",
       "17                   \"A5\"        \"22x22x22\"        \"B\"         \"90.98\"   \n",
       "18                   \"A5\"        \"22x22x22\"        \"B\"         \"90.98\"   \n",
       "19                   \"A5\"        \"22x22x22\"        \"B\"         \"90.98\"   \n",
       "20                  \"CB1\"        \"24x22x22\"        \"B\"            \"80\"   \n",
       "21        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "22        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "23        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "24        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "25        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "26        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "27        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "28        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "29        \"FirstCry Box2\"        \"24x20x20\"        \"B\"            \"90\"   \n",
       "..                    ...               ...        ...             ...   \n",
       "864      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "865      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "866      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "867      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "868      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "869      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "870      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "871      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "872      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "873      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "874      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "875      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "876      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "877      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "878      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "879      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "880      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "881      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "882      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "883      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "884      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "885      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "886      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "887      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "888      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "889      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "890      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "891      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "892      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "893      \"FirstCry Box3A\"        \"24x20x20\"        \"B\"           \"120\"   \n",
       "\n",
       "    height_inch inner_height length_inch  updated_at  quantity  status  \\\n",
       "0         \"3.9\"        \"687\"       \"7.9\"  2018-11-01       795       3   \n",
       "1         \"3.9\"        \"687\"       \"7.9\"  2018-11-01     12490       3   \n",
       "2        \"11.8\"        \"730\"      \"28.7\"  2018-02-07        10       3   \n",
       "3        \"11.8\"        \"730\"      \"28.7\"  2018-02-07      2165       3   \n",
       "4        \"11.8\"        \"730\"      \"28.7\"  2018-02-07       315       3   \n",
       "5        \"11.8\"        \"730\"      \"28.7\"  2018-02-07       825       3   \n",
       "6         \"4.1\"     \"306.88\"      \"12.2\"  2018-10-05      1000       4   \n",
       "7         \"4.1\"     \"306.88\"      \"12.2\"  2018-10-05      1998       3   \n",
       "8         \"4.1\"     \"306.88\"      \"12.2\"  2018-10-05      1000       1   \n",
       "9         \"4.1\"     \"306.88\"      \"12.2\"  2018-10-05      1000       3   \n",
       "10        \"4.1\"     \"306.88\"      \"12.2\"  2018-10-05      1000       3   \n",
       "11        \"4.1\"     \"306.88\"      \"12.2\"  2018-10-05       990       3   \n",
       "12        \"4.1\"     \"306.88\"      \"12.2\"  2018-10-05      1000       3   \n",
       "13        \"3.7\"     \"197.66\"       \"7.9\"  2018-10-05      1000       4   \n",
       "14        \"3.7\"     \"197.66\"       \"7.9\"  2018-10-05      1000       3   \n",
       "15        \"3.7\"     \"197.66\"       \"7.9\"  2018-10-05      1000       1   \n",
       "16        \"3.7\"     \"197.66\"       \"7.9\"  2018-10-05      2550       3   \n",
       "17        \"3.7\"     \"197.66\"       \"7.9\"  2018-10-05      1985       3   \n",
       "18        \"3.7\"     \"197.66\"       \"7.9\"  2018-10-05      1000       3   \n",
       "19        \"3.7\"     \"197.66\"       \"7.9\"  2018-10-05      1000       3   \n",
       "20        \"3.1\"        \"660\"        \"26\"  2018-11-01      3000       3   \n",
       "21          \"3\"        \"220\"         \"8\"  2019-06-12     13000       3   \n",
       "22          \"3\"        \"220\"         \"8\"  2019-06-12      3000       3   \n",
       "23          \"3\"        \"220\"         \"8\"  2018-03-19     28925       3   \n",
       "24          \"3\"        \"220\"         \"8\"  2019-06-12       755       3   \n",
       "25          \"3\"        \"220\"         \"8\"  2019-06-12     15000       3   \n",
       "26          \"3\"        \"220\"         \"8\"  2018-03-19     15000       3   \n",
       "27          \"3\"        \"220\"         \"8\"  2018-03-19     26174       3   \n",
       "28          \"3\"        \"220\"         \"8\"  2018-03-19     28550       3   \n",
       "29          \"3\"        \"220\"         \"8\"  2019-06-12      2950       3   \n",
       "..          ...          ...         ...         ...       ...     ...   \n",
       "864         \"4\"        \"250\"         \"9\"  2019-06-12      2800       3   \n",
       "865         \"4\"        \"250\"         \"9\"  2019-06-12      3040       3   \n",
       "866         \"4\"        \"250\"         \"9\"  2019-06-12      1200       3   \n",
       "867         \"4\"        \"250\"         \"9\"  2019-06-12     15000       3   \n",
       "868         \"4\"        \"250\"         \"9\"  2019-06-12      5000       3   \n",
       "869         \"4\"        \"250\"         \"9\"  2019-06-12     10000       8   \n",
       "870         \"4\"        \"250\"         \"9\"  2019-06-12      4000       3   \n",
       "871         \"4\"        \"250\"         \"9\"  2019-06-12     12000       3   \n",
       "872         \"4\"        \"250\"         \"9\"  2019-06-12         1       8   \n",
       "873         \"4\"        \"250\"         \"9\"  2019-06-12      5000       7   \n",
       "874         \"4\"        \"250\"         \"9\"  2018-02-05     44975       3   \n",
       "875         \"4\"        \"250\"         \"9\"  2019-06-12      5000       1   \n",
       "876         \"4\"        \"250\"         \"9\"  2019-06-12     10000       3   \n",
       "877         \"4\"        \"250\"         \"9\"  2019-06-12     30000       3   \n",
       "878         \"4\"        \"250\"         \"9\"  2019-06-12     30000       3   \n",
       "879         \"4\"        \"250\"         \"9\"  2019-06-12     20000       1   \n",
       "880         \"4\"        \"250\"         \"9\"  2019-06-12     10000       6   \n",
       "881         \"4\"        \"250\"         \"9\"  2019-06-12     10000       1   \n",
       "882         \"4\"        \"250\"         \"9\"  2019-06-12     15000       1   \n",
       "883         \"4\"        \"250\"         \"9\"  2019-06-12     11000       1   \n",
       "884         \"4\"        \"250\"         \"9\"  2019-06-12     15000       4   \n",
       "885         \"4\"        \"250\"         \"9\"  2019-06-12      2000       4   \n",
       "886         \"4\"        \"250\"         \"9\"  2019-06-12     15000       1   \n",
       "887         \"4\"        \"250\"         \"9\"  2019-06-12     30000       3   \n",
       "888         \"4\"        \"250\"         \"9\"  2019-06-12      5000       3   \n",
       "889         \"4\"        \"250\"         \"9\"  2019-06-12      9700       3   \n",
       "890         \"4\"        \"250\"         \"9\"  2019-06-12      3000       3   \n",
       "891         \"4\"        \"250\"         \"9\"  2019-06-12     10000       1   \n",
       "892         \"4\"        \"250\"         \"9\"  2019-06-12     20000       1   \n",
       "893         \"4\"        \"250\"         \"9\"  2019-06-12      2000       3   \n",
       "\n",
       "     company_id   per_unit  \n",
       "0          4606   6.710000  \n",
       "1          4606   7.100000  \n",
       "2          4606  63.430000  \n",
       "3          9508  67.000000  \n",
       "4          9508  67.000000  \n",
       "5          4606  67.229947  \n",
       "6          4606   6.930000  \n",
       "7          4606   7.340000  \n",
       "8          4606   6.930000  \n",
       "9          4606   7.860000  \n",
       "10         4606   7.860000  \n",
       "11         4606   7.860000  \n",
       "12         4606   7.345800  \n",
       "13         4606   4.430000  \n",
       "14         4606   5.020000  \n",
       "15         4606   4.430000  \n",
       "16         4606   5.020000  \n",
       "17         4606   4.680000  \n",
       "18         4606   5.020000  \n",
       "19         4606   4.695800  \n",
       "20         4606  41.210000  \n",
       "21         4606   4.380000  \n",
       "22         4606   4.380000  \n",
       "23         4606   4.380000  \n",
       "24         7746   4.060000  \n",
       "25         7746   4.060000  \n",
       "26         4606   4.380000  \n",
       "27         4606   4.290000  \n",
       "28         4606   4.639527  \n",
       "29         7746   3.870000  \n",
       "..          ...        ...  \n",
       "864        7746   7.130000  \n",
       "865        9508   7.200000  \n",
       "866        7746   7.130000  \n",
       "867        9508   7.200000  \n",
       "868        9508   7.200000  \n",
       "869        7746   7.130000  \n",
       "870        7746   7.130000  \n",
       "871        9508   7.200000  \n",
       "872        7746   7.130000  \n",
       "873        9508   7.200000  \n",
       "874        4606   7.960000  \n",
       "875        4606   7.700000  \n",
       "876        9508   7.600000  \n",
       "877        7746   7.130000  \n",
       "878        9508   7.200000  \n",
       "879        4606   7.700000  \n",
       "880        9508   7.600000  \n",
       "881        9508   7.200000  \n",
       "882        9508   7.200000  \n",
       "883        9508   7.200000  \n",
       "884        9508   1.000000  \n",
       "885        9508   7.600000  \n",
       "886        9508   6.800000  \n",
       "887        7746   7.000000  \n",
       "888        9508   7.600000  \n",
       "889        9508   7.200000  \n",
       "890        9508   7.600000  \n",
       "891        4606   7.700000  \n",
       "892        9508   7.200000  \n",
       "893        9508   7.600000  \n",
       "\n",
       "[894 rows x 14 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "data_location = \"s3://sagemaker-biz-demo/automatedpricing/data/base_prod.csv\"\n",
    "dataset = pd.read_csv(data_location)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.000e+00, 1.500e+01, ..., 7.950e+02, 3.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.500e+01, ..., 1.249e+04, 3.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.100e+01, 0.000e+00, 1.600e+01, ..., 1.000e+01, 3.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [7.000e+00, 1.000e+00, 7.000e+00, ..., 1.000e+04, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [7.000e+00, 1.000e+00, 7.000e+00, ..., 2.000e+04, 1.000e+00,\n",
       "        2.000e+00],\n",
       "       [7.000e+00, 1.000e+00, 7.000e+00, ..., 2.000e+03, 3.000e+00,\n",
       "        2.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Processing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "labelencoder_dataset = LabelEncoder()\n",
    "dataset[\"sku_code\"] = labelencoder_dataset.fit_transform(dataset[\"sku_code\"])\n",
    "dataset[\"material\"] = labelencoder_dataset.fit_transform(dataset[\"material\"])\n",
    "dataset[\"box_code\"] = labelencoder_dataset.fit_transform(dataset[\"box_code\"])\n",
    "dataset[\"bursting_factor\"] = labelencoder_dataset.fit_transform(dataset[\"bursting_factor\"])\n",
    "dataset[\"flute_type\"] = labelencoder_dataset.fit_transform(dataset[\"flute_type\"])\n",
    "dataset[\"updated_at\"] = labelencoder_dataset.fit_transform(dataset[\"updated_at\"])\n",
    "dataset[\"company_id\"] = labelencoder_dataset.fit_transform(dataset[\"company_id\"])\n",
    "\n",
    "dataset[\"inner_height_mm\"] = list(map(lambda x: float(x.replace(\"\\\"\", \"\" )), dataset[\"inner_height_mm\"]))\n",
    "dataset[\"height_inch\"] = list(map(lambda x: float(x.replace(\"\\\"\", \"\" )), dataset[\"height_inch\"]))\n",
    "dataset[\"inner_height\"] = list(map(lambda x: float(x.replace(\"\\\"\", \"\" )), dataset[\"inner_height\"]))\n",
    "dataset[\"length_inch\"] = list(map(lambda x: float(x.replace(\"\\\"\", \"\" )), dataset[\"length_inch\"]))\n",
    "\n",
    "modelData = np.array(dataset.iloc[:, 0:13]).astype('float32')\n",
    "target = np.array(dataset.iloc[:, 13]).astype('float32')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "modelData = sc_X.fit_transform(modelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "import io\n",
    "import os\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = \"sagemaker-biz-demo\"\n",
    "prefix = \"automatedpricing/test_results\"\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, modelData, target)\n",
    "buf.seek(0)\n",
    "\n",
    "key = 'linearlearner'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://sagemaker-biz-demo/automatedpricing/test_results/train/linearlearner\n",
      "training artifacts will be uploaded to: s3://sagemaker-biz-demo/automatedpricing/test_results/output\n"
     ]
    }
   ],
   "source": [
    "#defining region\n",
    "containers = {\n",
    "              'ap-south-1': '991648021394.dkr.ecr.ap-south-1.amazonaws.com/linear-learner:latest'\n",
    "              }\n",
    "\n",
    "containers[boto3.Session().region_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup execution \n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "linear = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                       role=role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c4.xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-07 07:30:01 Starting - Starting the training job...\n",
      "2019-07-07 07:30:05 Starting - Launching requested ML instances......\n",
      "2019-07-07 07:31:07 Starting - Preparing the instances for training......\n",
      "2019-07-07 07:32:29 Downloading - Downloading input data\n",
      "2019-07-07 07:32:29 Training - Downloading the training image..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'normalize_data': u'False', u'feature_dim': u'13', u'mini_batch_size': u'100', u'predictor_type': u'regressor'}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'13', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'False', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'100', u'huber_delta': u'1.0', u'num_classes': u'1', u'predictor_type': u'regressor', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 WARNING 139741542360896] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Using default worker.\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:44.295] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 14, \"num_examples\": 1, \"num_bytes\": 9600}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Create Store: local\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:44.323] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 28, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f17cc1a6e10>\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Scaling model computed with parameters:\n",
      " {'stdev_weight': None, 'stdev_label': \u001b[0m\n",
      "\u001b[31m[19.983997]\u001b[0m\n",
      "\u001b[31m<NDArray 1 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[31m[20.866201]\u001b[0m\n",
      "\u001b[31m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[31m[ 0.11578503 -0.05693686  0.06530111 -0.05671909  0.06378817  0.07927102\n",
      "  0.0825654   0.09142841  0.09909758  0.0049622  -0.0647031  -0.00450209\n",
      " -0.02069804]\u001b[0m\n",
      "\u001b[31m<NDArray 13 @cpu(0)>}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] nvidia-smi took: 0.0252559185028 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Total Records Seen\": {\"count\": 1, \"max\": 994, \"sum\": 994.0, \"min\": 994}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1562484764.421474, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1562484764.421442}\n",
      "\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:44.573] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 151, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7251151994615793, \"sum\": 0.7251151994615793, \"min\": 0.7251151994615793}}, \"EndTime\": 1562484764.573427, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573341}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2154225884377956, \"sum\": 1.2154225884377956, \"min\": 1.2154225884377956}}, \"EndTime\": 1562484764.573512, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.57349}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7788066923618316, \"sum\": 0.7788066923618316, \"min\": 0.7788066923618316}}, \"EndTime\": 1562484764.573584, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573565}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.258739852309227, \"sum\": 1.258739852309227, \"min\": 1.258739852309227}}, \"EndTime\": 1562484764.573648, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573629}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0446759140491486, \"sum\": 1.0446759140491486, \"min\": 1.0446759140491486}}, \"EndTime\": 1562484764.573721, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573701}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8764495623111724, \"sum\": 0.8764495623111724, \"min\": 0.8764495623111724}}, \"EndTime\": 1562484764.573794, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573774}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8823386144638061, \"sum\": 0.8823386144638061, \"min\": 0.8823386144638061}}, \"EndTime\": 1562484764.573864, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573845}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9687244403362274, \"sum\": 0.9687244403362274, \"min\": 0.9687244403362274}}, \"EndTime\": 1562484764.573926, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573908}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2425736685097217, \"sum\": 1.2425736685097217, \"min\": 1.2425736685097217}}, \"EndTime\": 1562484764.573994, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.573975}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7402971990779043, \"sum\": 0.7402971990779043, \"min\": 0.7402971990779043}}, \"EndTime\": 1562484764.574054, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574036}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9727659273147583, \"sum\": 0.9727659273147583, \"min\": 0.9727659273147583}}, \"EndTime\": 1562484764.574124, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574106}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9231647375226021, \"sum\": 0.9231647375226021, \"min\": 0.9231647375226021}}, \"EndTime\": 1562484764.574192, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574174}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8541046142578125, \"sum\": 0.8541046142578125, \"min\": 0.8541046142578125}}, \"EndTime\": 1562484764.574262, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574243}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9734542727470398, \"sum\": 0.9734542727470398, \"min\": 0.9734542727470398}}, \"EndTime\": 1562484764.57433, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574312}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9192921662330628, \"sum\": 0.9192921662330628, \"min\": 0.9192921662330628}}, \"EndTime\": 1562484764.574401, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574382}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9347172915935517, \"sum\": 0.9347172915935517, \"min\": 0.9347172915935517}}, \"EndTime\": 1562484764.57447, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574452}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8511907823383809, \"sum\": 0.8511907823383809, \"min\": 0.8511907823383809}}, \"EndTime\": 1562484764.57454, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574523}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.786504445001483, \"sum\": 0.786504445001483, \"min\": 0.786504445001483}}, \"EndTime\": 1562484764.574598, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574582}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8786771165952086, \"sum\": 0.8786771165952086, \"min\": 0.8786771165952086}}, \"EndTime\": 1562484764.574657, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574639}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8192584845423698, \"sum\": 0.8192584845423698, \"min\": 0.8192584845423698}}, \"EndTime\": 1562484764.574714, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574698}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7543857073783875, \"sum\": 0.7543857073783875, \"min\": 0.7543857073783875}}, \"EndTime\": 1562484764.574749, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.57474}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7627477830648423, \"sum\": 0.7627477830648423, \"min\": 0.7627477830648423}}, \"EndTime\": 1562484764.574804, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574787}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7996871861815452, \"sum\": 0.7996871861815452, \"min\": 0.7996871861815452}}, \"EndTime\": 1562484764.57487, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574852}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7822112309932708, \"sum\": 0.7822112309932708, \"min\": 0.7822112309932708}}, \"EndTime\": 1562484764.57494, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574922}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1020432305708527, \"sum\": 1.1020432305708527, \"min\": 1.1020432305708527}}, \"EndTime\": 1562484764.575, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.574983}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0179366336762905, \"sum\": 1.0179366336762905, \"min\": 1.0179366336762905}}, \"EndTime\": 1562484764.575069, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.575051}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1021053986996412, \"sum\": 1.1021053986996412, \"min\": 1.1021053986996412}}, \"EndTime\": 1562484764.57513, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.575113}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1060053506866097, \"sum\": 1.1060053506866097, \"min\": 1.1060053506866097}}, \"EndTime\": 1562484764.575192, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.575174}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1505240294337273, \"sum\": 1.1505240294337273, \"min\": 1.1505240294337273}}, \"EndTime\": 1562484764.57526, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.575242}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0859732270240783, \"sum\": 1.0859732270240783, \"min\": 1.0859732270240783}}, \"EndTime\": 1562484764.575324, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.575306}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0355138254538179, \"sum\": 1.0355138254538179, \"min\": 1.0355138254538179}}, \"EndTime\": 1562484764.575383, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.575367}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9917299629002809, \"sum\": 0.9917299629002809, \"min\": 0.9917299629002809}}, \"EndTime\": 1562484764.57544, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.575423}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #quality_metric: host=algo-1, epoch=0, train mse_objective <loss>=0.725115199462\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=mse_objective, value=0.725115199462\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}, \"Total Records Seen\": {\"count\": 1, \"max\": 1888, \"sum\": 1888.0, \"min\": 1888}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1562484764.578471, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1562484764.421655}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5696.66145977 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:44.725] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 146, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.3866459491848946, \"sum\": 0.3866459491848946, \"min\": 0.3866459491848946}}, \"EndTime\": 1562484764.725519, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725441}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7066835128515959, \"sum\": 0.7066835128515959, \"min\": 0.7066835128515959}}, \"EndTime\": 1562484764.725595, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725576}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.41012281127274036, \"sum\": 0.41012281127274036, \"min\": 0.41012281127274036}}, \"EndTime\": 1562484764.725659, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725641}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7462861831486225, \"sum\": 0.7462861831486225, \"min\": 0.7462861831486225}}, \"EndTime\": 1562484764.725709, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725698}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.7955376482009888, \"sum\": 1.7955376482009888, \"min\": 1.7955376482009888}}, \"EndTime\": 1562484764.725767, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725749}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.5281765365600586, \"sum\": 1.5281765365600586, \"min\": 1.5281765365600586}}, \"EndTime\": 1562484764.725838, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725819}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.5866631412506103, \"sum\": 1.5866631412506103, \"min\": 1.5866631412506103}}, \"EndTime\": 1562484764.72591, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725891}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.5670541334152222, \"sum\": 1.5670541334152222, \"min\": 1.5670541334152222}}, \"EndTime\": 1562484764.725981, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.725963}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7321359911561012, \"sum\": 0.7321359911561012, \"min\": 0.7321359911561012}}, \"EndTime\": 1562484764.726051, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726033}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.39108608074486256, \"sum\": 0.39108608074486256, \"min\": 0.39108608074486256}}, \"EndTime\": 1562484764.726109, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726093}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.5414904300868512, \"sum\": 0.5414904300868512, \"min\": 0.5414904300868512}}, \"EndTime\": 1562484764.726166, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.72615}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.5136084482073784, \"sum\": 0.5136084482073784, \"min\": 0.5136084482073784}}, \"EndTime\": 1562484764.726223, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726206}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.3566744804382325, \"sum\": 1.3566744804382325, \"min\": 1.3566744804382325}}, \"EndTime\": 1562484764.726291, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726273}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.8361982083320618, \"sum\": 1.8361982083320618, \"min\": 1.8361982083320618}}, \"EndTime\": 1562484764.726352, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726335}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.4062920689582825, \"sum\": 1.4062920689582825, \"min\": 1.4062920689582825}}, \"EndTime\": 1562484764.726412, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726395}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.464948296546936, \"sum\": 1.464948296546936, \"min\": 1.464948296546936}}, \"EndTime\": 1562484764.726472, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726454}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.4669905259460211, \"sum\": 0.4669905259460211, \"min\": 0.4669905259460211}}, \"EndTime\": 1562484764.726532, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726514}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.43492063954472543, \"sum\": 0.43492063954472543, \"min\": 0.43492063954472543}}, \"EndTime\": 1562484764.726592, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726575}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.47984370298683643, \"sum\": 0.47984370298683643, \"min\": 0.47984370298683643}}, \"EndTime\": 1562484764.726663, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726644}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.4504253078997135, \"sum\": 0.4504253078997135, \"min\": 0.4504253078997135}}, \"EndTime\": 1562484764.726736, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726717}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1383658277988433, \"sum\": 1.1383658277988433, \"min\": 1.1383658277988433}}, \"EndTime\": 1562484764.726809, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.72679}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0920511889457702, \"sum\": 1.0920511889457702, \"min\": 1.0920511889457702}}, \"EndTime\": 1562484764.726878, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.72686}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.214091305732727, \"sum\": 1.214091305732727, \"min\": 1.214091305732727}}, \"EndTime\": 1562484764.726941, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726924}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9649679255485535, \"sum\": 0.9649679255485535, \"min\": 0.9649679255485535}}, \"EndTime\": 1562484764.72701, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.726991}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9186813506111503, \"sum\": 0.9186813506111503, \"min\": 0.9186813506111503}}, \"EndTime\": 1562484764.727073, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.727055}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9115062227472663, \"sum\": 0.9115062227472663, \"min\": 0.9115062227472663}}, \"EndTime\": 1562484764.727138, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.72712}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9745964083075523, \"sum\": 0.9745964083075523, \"min\": 0.9745964083075523}}, \"EndTime\": 1562484764.727203, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.727186}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9260334540903569, \"sum\": 0.9260334540903569, \"min\": 0.9260334540903569}}, \"EndTime\": 1562484764.727262, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.727245}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 2.0843462336063383, \"sum\": 2.0843462336063383, \"min\": 2.0843462336063383}}, \"EndTime\": 1562484764.727321, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.727309}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 2.008308856487274, \"sum\": 2.008308856487274, \"min\": 2.008308856487274}}, \"EndTime\": 1562484764.727378, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.72736}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 2.160559577345848, \"sum\": 2.160559577345848, \"min\": 2.160559577345848}}, \"EndTime\": 1562484764.727448, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.727429}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 2.198975199609995, \"sum\": 2.198975199609995, \"min\": 2.198975199609995}}, \"EndTime\": 1562484764.727516, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.727498}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #quality_metric: host=algo-1, epoch=1, train mse_objective <loss>=0.386645949185\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=mse_objective, value=0.386645949185\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}, \"Total Records Seen\": {\"count\": 1, \"max\": 2782, \"sum\": 2782.0, \"min\": 2782}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1562484764.730091, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1562484764.578752}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5903.01577251 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:44.888] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 157, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.23702066853642464, \"sum\": 0.23702066853642464, \"min\": 0.23702066853642464}}, \"EndTime\": 1562484764.888523, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888434}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.42506746768951414, \"sum\": 0.42506746768951414, \"min\": 0.42506746768951414}}, \"EndTime\": 1562484764.888595, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888578}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.23538071408867836, \"sum\": 0.23538071408867836, \"min\": 0.23538071408867836}}, \"EndTime\": 1562484764.888655, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888637}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.4597895646095276, \"sum\": 0.4597895646095276, \"min\": 0.4597895646095276}}, \"EndTime\": 1562484764.888708, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888693}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.7456497597694396, \"sum\": 1.7456497597694396, \"min\": 1.7456497597694396}}, \"EndTime\": 1562484764.888767, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888749}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.5988298273086547, \"sum\": 1.5988298273086547, \"min\": 1.5988298273086547}}, \"EndTime\": 1562484764.888855, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888836}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.7409086263179778, \"sum\": 1.7409086263179778, \"min\": 1.7409086263179778}}, \"EndTime\": 1562484764.888916, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888899}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.6777083653211593, \"sum\": 1.6777083653211593, \"min\": 1.6777083653211593}}, \"EndTime\": 1562484764.888976, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.888957}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.4477369007468224, \"sum\": 0.4477369007468224, \"min\": 0.4477369007468224}}, \"EndTime\": 1562484764.889025, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.88901}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.23323914051055908, \"sum\": 0.23323914051055908, \"min\": 0.23323914051055908}}, \"EndTime\": 1562484764.889084, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889067}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.3217426180839539, \"sum\": 0.3217426180839539, \"min\": 0.3217426180839539}}, \"EndTime\": 1562484764.889142, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889125}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.3092386943101883, \"sum\": 0.3092386943101883, \"min\": 0.3092386943101883}}, \"EndTime\": 1562484764.889199, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889182}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.3107454729080201, \"sum\": 1.3107454729080201, \"min\": 1.3107454729080201}}, \"EndTime\": 1562484764.889258, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889241}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.9815525126457214, \"sum\": 1.9815525126457214, \"min\": 1.9815525126457214}}, \"EndTime\": 1562484764.889316, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889299}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.5660576444864274, \"sum\": 1.5660576444864274, \"min\": 1.5660576444864274}}, \"EndTime\": 1562484764.889368, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889354}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.4265138787031173, \"sum\": 1.4265138787031173, \"min\": 1.4265138787031173}}, \"EndTime\": 1562484764.889425, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889408}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.27978639766573904, \"sum\": 0.27978639766573904, \"min\": 0.27978639766573904}}, \"EndTime\": 1562484764.889484, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889467}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2739093279838562, \"sum\": 0.2739093279838562, \"min\": 0.2739093279838562}}, \"EndTime\": 1562484764.889546, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889528}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2822721339762211, \"sum\": 0.2822721339762211, \"min\": 0.2822721339762211}}, \"EndTime\": 1562484764.889607, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889589}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2782746021449566, \"sum\": 0.2782746021449566, \"min\": 0.2782746021449566}}, \"EndTime\": 1562484764.889667, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.88965}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.6888888514041901, \"sum\": 0.6888888514041901, \"min\": 0.6888888514041901}}, \"EndTime\": 1562484764.889729, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889711}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.5762169355154038, \"sum\": 0.5762169355154038, \"min\": 0.5762169355154038}}, \"EndTime\": 1562484764.889799, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.88978}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7137289714813232, \"sum\": 0.7137289714813232, \"min\": 0.7137289714813232}}, \"EndTime\": 1562484764.889868, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.88985}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.470800923705101, \"sum\": 0.470800923705101, \"min\": 0.470800923705101}}, \"EndTime\": 1562484764.889928, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.88991}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8711273331940174, \"sum\": 0.8711273331940174, \"min\": 0.8711273331940174}}, \"EndTime\": 1562484764.889982, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.889967}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9066865386068821, \"sum\": 0.9066865386068821, \"min\": 0.9066865386068821}}, \"EndTime\": 1562484764.890038, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.890022}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8828188203275203, \"sum\": 0.8828188203275203, \"min\": 0.8828188203275203}}, \"EndTime\": 1562484764.890106, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.890088}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8885383895039558, \"sum\": 0.8885383895039558, \"min\": 0.8885383895039558}}, \"EndTime\": 1562484764.890178, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.890159}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0099291633814573, \"sum\": 1.0099291633814573, \"min\": 1.0099291633814573}}, \"EndTime\": 1562484764.890247, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.890229}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9689390508458018, \"sum\": 0.9689390508458018, \"min\": 0.9689390508458018}}, \"EndTime\": 1562484764.890308, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.89029}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9426018155366183, \"sum\": 0.9426018155366183, \"min\": 0.9426018155366183}}, \"EndTime\": 1562484764.890384, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.890364}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9563584426417947, \"sum\": 0.9563584426417947, \"min\": 0.9563584426417947}}, \"EndTime\": 1562484764.890456, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.890437}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #quality_metric: host=algo-1, epoch=2, train mse_objective <loss>=0.237020668536\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=mse_objective, value=0.233239140511\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}, \"Total Records Seen\": {\"count\": 1, \"max\": 3676, \"sum\": 3676.0, \"min\": 3676}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1562484764.893268, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1562484764.730347}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:44 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5482.78239407 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:45.060] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 166, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1818315176665783, \"sum\": 0.1818315176665783, \"min\": 0.1818315176665783}}, \"EndTime\": 1562484765.060172, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.06008}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2732149538397789, \"sum\": 0.2732149538397789, \"min\": 0.2732149538397789}}, \"EndTime\": 1562484765.060261, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060242}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.16458206802606581, \"sum\": 0.16458206802606581, \"min\": 0.16458206802606581}}, \"EndTime\": 1562484765.06032, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060304}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.3019721147418022, \"sum\": 0.3019721147418022, \"min\": 0.3019721147418022}}, \"EndTime\": 1562484765.060384, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060367}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0881019687652589, \"sum\": 1.0881019687652589, \"min\": 1.0881019687652589}}, \"EndTime\": 1562484765.060447, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060429}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.4781500321626664, \"sum\": 1.4781500321626664, \"min\": 1.4781500321626664}}, \"EndTime\": 1562484765.060508, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060491}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.3883811855316162, \"sum\": 1.3883811855316162, \"min\": 1.3883811855316162}}, \"EndTime\": 1562484765.060567, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060549}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.305819182395935, \"sum\": 1.305819182395935, \"min\": 1.305819182395935}}, \"EndTime\": 1562484765.060631, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060613}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.29146484792232513, \"sum\": 0.29146484792232513, \"min\": 0.29146484792232513}}, \"EndTime\": 1562484765.060688, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060669}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.17470523655414583, \"sum\": 0.17470523655414583, \"min\": 0.17470523655414583}}, \"EndTime\": 1562484765.060755, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060737}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2173932135105133, \"sum\": 0.2173932135105133, \"min\": 0.2173932135105133}}, \"EndTime\": 1562484765.060852, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060831}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.21628676503896713, \"sum\": 0.21628676503896713, \"min\": 0.21628676503896713}}, \"EndTime\": 1562484765.060919, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.0609}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.4102751737833024, \"sum\": 1.4102751737833024, \"min\": 1.4102751737833024}}, \"EndTime\": 1562484765.060985, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.060966}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.329101881980896, \"sum\": 1.329101881980896, \"min\": 1.329101881980896}}, \"EndTime\": 1562484765.061049, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061031}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.370254477262497, \"sum\": 1.370254477262497, \"min\": 1.370254477262497}}, \"EndTime\": 1562484765.061115, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061095}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.3429786667227746, \"sum\": 1.3429786667227746, \"min\": 1.3429786667227746}}, \"EndTime\": 1562484765.061181, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061162}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.19618055015802383, \"sum\": 0.19618055015802383, \"min\": 0.19618055015802383}}, \"EndTime\": 1562484765.061244, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061226}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.20482777267694474, \"sum\": 0.20482777267694474, \"min\": 0.20482777267694474}}, \"EndTime\": 1562484765.06131, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061291}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.19239401936531067, \"sum\": 0.19239401936531067, \"min\": 0.19239401936531067}}, \"EndTime\": 1562484765.061373, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061355}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.20506029680371285, \"sum\": 0.20506029680371285, \"min\": 0.20506029680371285}}, \"EndTime\": 1562484765.061437, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061421}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.280983583331108, \"sum\": 1.280983583331108, \"min\": 1.280983583331108}}, \"EndTime\": 1562484765.061499, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061481}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9620947118103504, \"sum\": 0.9620947118103504, \"min\": 0.9620947118103504}}, \"EndTime\": 1562484765.061559, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061543}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1255578863620759, \"sum\": 1.1255578863620759, \"min\": 1.1255578863620759}}, \"EndTime\": 1562484765.06162, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061602}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7912501727044582, \"sum\": 0.7912501727044582, \"min\": 0.7912501727044582}}, \"EndTime\": 1562484765.061692, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061672}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8985212764143944, \"sum\": 0.8985212764143944, \"min\": 0.8985212764143944}}, \"EndTime\": 1562484765.061764, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061745}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8985477542877197, \"sum\": 0.8985477542877197, \"min\": 0.8985477542877197}}, \"EndTime\": 1562484765.061827, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061808}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8714586225152016, \"sum\": 0.8714586225152016, \"min\": 0.8714586225152016}}, \"EndTime\": 1562484765.061887, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.06187}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8852162817120552, \"sum\": 0.8852162817120552, \"min\": 0.8852162817120552}}, \"EndTime\": 1562484765.061957, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.061938}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1947502541542052, \"sum\": 1.1947502541542052, \"min\": 1.1947502541542052}}, \"EndTime\": 1562484765.062018, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.062}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2948222386837005, \"sum\": 1.2948222386837005, \"min\": 1.2948222386837005}}, \"EndTime\": 1562484765.062079, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.062062}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.3287440383434295, \"sum\": 1.3287440383434295, \"min\": 1.3287440383434295}}, \"EndTime\": 1562484765.062147, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.062129}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.325848845243454, \"sum\": 1.325848845243454, \"min\": 1.325848845243454}}, \"EndTime\": 1562484765.062217, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484765.062199}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #quality_metric: host=algo-1, epoch=3, train mse_objective <loss>=0.181831517667\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=mse_objective, value=0.164582068026\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}, \"Total Records Seen\": {\"count\": 1, \"max\": 4570, \"sum\": 4570.0, \"min\": 4570}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1562484765.065142, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1562484764.893555}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5205.91017647 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:45.227] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 162, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1652586928009987, \"sum\": 0.1652586928009987, \"min\": 0.1652586928009987}}, \"EndTime\": 1562484765.227726, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.227665}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.20647308498620986, \"sum\": 0.20647308498620986, \"min\": 0.20647308498620986}}, \"EndTime\": 1562484765.22781, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.227796}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14403086096048356, \"sum\": 0.14403086096048356, \"min\": 0.14403086096048356}}, \"EndTime\": 1562484765.227848, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.227839}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.22931197464466094, \"sum\": 0.22931197464466094, \"min\": 0.22931197464466094}}, \"EndTime\": 1562484765.227878, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.22787}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.5537214803695679, \"sum\": 0.5537214803695679, \"min\": 0.5537214803695679}}, \"EndTime\": 1562484765.227909, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.227899}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.067274272441864, \"sum\": 1.067274272441864, \"min\": 1.067274272441864}}, \"EndTime\": 1562484765.22796, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.227946}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8182710313796997, \"sum\": 0.8182710313796997, \"min\": 0.8182710313796997}}, \"EndTime\": 1562484765.228019, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228001}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8627189874649048, \"sum\": 0.8627189874649048, \"min\": 0.8627189874649048}}, \"EndTime\": 1562484765.228079, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228062}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.21911381781101227, \"sum\": 0.21911381781101227, \"min\": 0.21911381781101227}}, \"EndTime\": 1562484765.228139, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228122}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15912350833415986, \"sum\": 0.15912350833415986, \"min\": 0.15912350833415986}}, \"EndTime\": 1562484765.228198, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228181}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.17827031195163726, \"sum\": 0.17827031195163726, \"min\": 0.17827031195163726}}, \"EndTime\": 1562484765.228259, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228242}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.18335772931575775, \"sum\": 0.18335772931575775, \"min\": 0.18335772931575775}}, \"EndTime\": 1562484765.228318, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228301}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.137880232334137, \"sum\": 1.137880232334137, \"min\": 1.137880232334137}}, \"EndTime\": 1562484765.228362, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228348}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.6540094542503357, \"sum\": 0.6540094542503357, \"min\": 0.6540094542503357}}, \"EndTime\": 1562484765.228418, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228403}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9462958765029907, \"sum\": 0.9462958765029907, \"min\": 0.9462958765029907}}, \"EndTime\": 1562484765.228469, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228458}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0760937213897706, \"sum\": 1.0760937213897706, \"min\": 1.0760937213897706}}, \"EndTime\": 1562484765.228498, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228491}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.16470647603273392, \"sum\": 0.16470647603273392, \"min\": 0.16470647603273392}}, \"EndTime\": 1562484765.228525, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228518}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.17639280676841737, \"sum\": 0.17639280676841737, \"min\": 0.17639280676841737}}, \"EndTime\": 1562484765.228558, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228546}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15912173360586165, \"sum\": 0.15912173360586165, \"min\": 0.15912173360586165}}, \"EndTime\": 1562484765.228613, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228597}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.17746920071542263, \"sum\": 0.17746920071542263, \"min\": 0.17746920071542263}}, \"EndTime\": 1562484765.228669, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228653}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0065619564056396, \"sum\": 1.0065619564056396, \"min\": 1.0065619564056396}}, \"EndTime\": 1562484765.228726, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228711}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7269276523590088, \"sum\": 0.7269276523590088, \"min\": 0.7269276523590088}}, \"EndTime\": 1562484765.228809, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228768}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.7362782680988311, \"sum\": 0.7362782680988311, \"min\": 0.7362782680988311}}, \"EndTime\": 1562484765.228872, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228854}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.5554773032665252, \"sum\": 0.5554773032665252, \"min\": 0.5554773032665252}}, \"EndTime\": 1562484765.228924, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228908}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9014583569765091, \"sum\": 0.9014583569765091, \"min\": 0.9014583569765091}}, \"EndTime\": 1562484765.228982, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.228965}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8934725165367127, \"sum\": 0.8934725165367127, \"min\": 0.8934725165367127}}, \"EndTime\": 1562484765.22904, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.229023}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8866156119108201, \"sum\": 0.8866156119108201, \"min\": 0.8866156119108201}}, \"EndTime\": 1562484765.229099, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.229083}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8954563531279564, \"sum\": 0.8954563531279564, \"min\": 0.8954563531279564}}, \"EndTime\": 1562484765.229145, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.229135}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1841565443947912, \"sum\": 1.1841565443947912, \"min\": 1.1841565443947912}}, \"EndTime\": 1562484765.229199, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.229183}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2181251790188252, \"sum\": 1.2181251790188252, \"min\": 1.2181251790188252}}, \"EndTime\": 1562484765.229271, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.229241}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1729905348829925, \"sum\": 1.1729905348829925, \"min\": 1.1729905348829925}}, \"EndTime\": 1562484765.229341, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.229323}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2153129901364446, \"sum\": 1.2153129901364446, \"min\": 1.2153129901364446}}, \"EndTime\": 1562484765.229394, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.229382}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #quality_metric: host=algo-1, epoch=4, train mse_objective <loss>=0.165258692801\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=mse_objective, value=0.14403086096\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}, \"Total Records Seen\": {\"count\": 1, \"max\": 5464, \"sum\": 5464.0, \"min\": 5464}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1562484765.232046, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1562484765.065435}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5362.25617852 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:45.368] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 136, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15347023367881774, \"sum\": 0.15347023367881774, \"min\": 0.15347023367881774}}, \"EndTime\": 1562484765.368992, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.368901}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.18061432093381882, \"sum\": 0.18061432093381882, \"min\": 0.18061432093381882}}, \"EndTime\": 1562484765.369068, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369048}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13532333046197892, \"sum\": 0.13532333046197892, \"min\": 0.13532333046197892}}, \"EndTime\": 1562484765.369143, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369126}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.19880784630775453, \"sum\": 0.19880784630775453, \"min\": 0.19880784630775453}}, \"EndTime\": 1562484765.3692, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369183}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11355049788951874, \"sum\": 0.11355049788951874, \"min\": 0.11355049788951874}}, \"EndTime\": 1562484765.36924, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.36923}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.3466522133350372, \"sum\": 0.3466522133350372, \"min\": 0.3466522133350372}}, \"EndTime\": 1562484765.369268, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369261}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.19582440257072448, \"sum\": 0.19582440257072448, \"min\": 0.19582440257072448}}, \"EndTime\": 1562484765.369316, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369301}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.23878151953220367, \"sum\": 0.23878151953220367, \"min\": 0.23878151953220367}}, \"EndTime\": 1562484765.369373, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369356}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.18841560423374176, \"sum\": 0.18841560423374176, \"min\": 0.18841560423374176}}, \"EndTime\": 1562484765.369409, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369401}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14978302270174026, \"sum\": 0.14978302270174026, \"min\": 0.14978302270174026}}, \"EndTime\": 1562484765.369437, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.36943}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1625794267654419, \"sum\": 0.1625794267654419, \"min\": 0.1625794267654419}}, \"EndTime\": 1562484765.369484, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369469}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.16882355034351348, \"sum\": 0.16882355034351348, \"min\": 0.16882355034351348}}, \"EndTime\": 1562484765.369539, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369524}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.4558951687812805, \"sum\": 0.4558951687812805, \"min\": 0.4558951687812805}}, \"EndTime\": 1562484765.369571, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369563}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12861806422472, \"sum\": 0.12861806422472, \"min\": 0.12861806422472}}, \"EndTime\": 1562484765.369598, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369591}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2817385017871857, \"sum\": 0.2817385017871857, \"min\": 0.2817385017871857}}, \"EndTime\": 1562484765.369624, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369617}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.4207274866104126, \"sum\": 0.4207274866104126, \"min\": 0.4207274866104126}}, \"EndTime\": 1562484765.369659, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369646}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15056100040674208, \"sum\": 0.15056100040674208, \"min\": 0.15056100040674208}}, \"EndTime\": 1562484765.36971, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369695}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15923834562301636, \"sum\": 0.15923834562301636, \"min\": 0.15923834562301636}}, \"EndTime\": 1562484765.36975, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369741}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14562828779220582, \"sum\": 0.14562828779220582, \"min\": 0.14562828779220582}}, \"EndTime\": 1562484765.369778, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369771}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.16305627048015595, \"sum\": 0.16305627048015595, \"min\": 0.16305627048015595}}, \"EndTime\": 1562484765.369804, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369797}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.4496816132962704, \"sum\": 1.4496816132962704, \"min\": 1.4496816132962704}}, \"EndTime\": 1562484765.369829, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369823}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.5686430531740188, \"sum\": 1.5686430531740188, \"min\": 1.5686430531740188}}, \"EndTime\": 1562484765.369858, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.36985}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1724607568979264, \"sum\": 1.1724607568979264, \"min\": 1.1724607568979264}}, \"EndTime\": 1562484765.369905, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.36989}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.3798425585031509, \"sum\": 1.3798425585031509, \"min\": 1.3798425585031509}}, \"EndTime\": 1562484765.369959, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369944}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8998221135139466, \"sum\": 0.8998221135139466, \"min\": 0.8998221135139466}}, \"EndTime\": 1562484765.369991, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.369983}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8983782094717025, \"sum\": 0.8983782094717025, \"min\": 0.8983782094717025}}, \"EndTime\": 1562484765.370017, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.37001}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9025614422559738, \"sum\": 0.9025614422559738, \"min\": 0.9025614422559738}}, \"EndTime\": 1562484765.370044, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.370037}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9042759144306183, \"sum\": 0.9042759144306183, \"min\": 0.9042759144306183}}, \"EndTime\": 1562484765.370069, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.370062}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.089303315281868, \"sum\": 1.089303315281868, \"min\": 1.089303315281868}}, \"EndTime\": 1562484765.370095, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.370088}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1278529012203216, \"sum\": 1.1278529012203216, \"min\": 1.1278529012203216}}, \"EndTime\": 1562484765.370145, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.37013}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.105018926858902, \"sum\": 1.105018926858902, \"min\": 1.105018926858902}}, \"EndTime\": 1562484765.370198, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.370183}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.139223438501358, \"sum\": 1.139223438501358, \"min\": 1.139223438501358}}, \"EndTime\": 1562484765.370242, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.370232}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #quality_metric: host=algo-1, epoch=5, train mse_objective <loss>=0.153470233679\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=mse_objective, value=0.11355049789\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 64, \"sum\": 64.0, \"min\": 64}, \"Total Records Seen\": {\"count\": 1, \"max\": 6358, \"sum\": 6358.0, \"min\": 6358}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1562484765.372855, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1562484765.232274}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=6353.76769832 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:45.526] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 153, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13962155669927598, \"sum\": 0.13962155669927598, \"min\": 0.13962155669927598}}, \"EndTime\": 1562484765.526982, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.526877}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1671035635471344, \"sum\": 0.1671035635471344, \"min\": 0.1671035635471344}}, \"EndTime\": 1562484765.527069, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527048}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1257461467385292, \"sum\": 0.1257461467385292, \"min\": 0.1257461467385292}}, \"EndTime\": 1562484765.527173, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527151}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.18220692813396455, \"sum\": 0.18220692813396455, \"min\": 0.18220692813396455}}, \"EndTime\": 1562484765.527237, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527219}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09509944442659617, \"sum\": 0.09509944442659617, \"min\": 0.09509944442659617}}, \"EndTime\": 1562484765.527355, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527334}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.18348944127559663, \"sum\": 0.18348944127559663, \"min\": 0.18348944127559663}}, \"EndTime\": 1562484765.527417, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.5274}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10848954051733017, \"sum\": 0.10848954051733017, \"min\": 0.10848954051733017}}, \"EndTime\": 1562484765.527523, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527501}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13545653700828553, \"sum\": 0.13545653700828553, \"min\": 0.13545653700828553}}, \"EndTime\": 1562484765.527587, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527569}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.17215520083904268, \"sum\": 0.17215520083904268, \"min\": 0.17215520083904268}}, \"EndTime\": 1562484765.527685, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527665}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13788896039128304, \"sum\": 0.13788896039128304, \"min\": 0.13788896039128304}}, \"EndTime\": 1562484765.527747, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527729}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1503281784057617, \"sum\": 0.1503281784057617, \"min\": 0.1503281784057617}}, \"EndTime\": 1562484765.52785, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.52783}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15517174303531647, \"sum\": 0.15517174303531647, \"min\": 0.15517174303531647}}, \"EndTime\": 1562484765.52791, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527892}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2515276753902435, \"sum\": 0.2515276753902435, \"min\": 0.2515276753902435}}, \"EndTime\": 1562484765.528029, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.527981}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.0971282760053873, \"sum\": 0.0971282760053873, \"min\": 0.0971282760053873}}, \"EndTime\": 1562484765.528095, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528078}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14278704285621643, \"sum\": 0.14278704285621643, \"min\": 0.14278704285621643}}, \"EndTime\": 1562484765.528182, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528138}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.25394608080387115, \"sum\": 0.25394608080387115, \"min\": 0.25394608080387115}}, \"EndTime\": 1562484765.528276, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528231}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14156060934066772, \"sum\": 0.14156060934066772, \"min\": 0.14156060934066772}}, \"EndTime\": 1562484765.528342, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528325}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1464065855741501, \"sum\": 0.1464065855741501, \"min\": 0.1464065855741501}}, \"EndTime\": 1562484765.528436, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528384}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13772646874189376, \"sum\": 0.13772646874189376, \"min\": 0.13772646874189376}}, \"EndTime\": 1562484765.528511, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528491}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15268741153180598, \"sum\": 0.15268741153180598, \"min\": 0.15268741153180598}}, \"EndTime\": 1562484765.528614, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528563}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8203523588180542, \"sum\": 0.8203523588180542, \"min\": 0.8203523588180542}}, \"EndTime\": 1562484765.52869, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528671}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2760265719890596, \"sum\": 1.2760265719890596, \"min\": 1.2760265719890596}}, \"EndTime\": 1562484765.528791, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528753}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.6728906632959842, \"sum\": 0.6728906632959842, \"min\": 0.6728906632959842}}, \"EndTime\": 1562484765.528838, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528828}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2726359409093857, \"sum\": 1.2726359409093857, \"min\": 1.2726359409093857}}, \"EndTime\": 1562484765.528889, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528872}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9073673564195633, \"sum\": 0.9073673564195633, \"min\": 0.9073673564195633}}, \"EndTime\": 1562484765.528972, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.528958}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9097115260362625, \"sum\": 0.9097115260362625, \"min\": 0.9097115260362625}}, \"EndTime\": 1562484765.52904, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.529021}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.912674930691719, \"sum\": 0.912674930691719, \"min\": 0.912674930691719}}, \"EndTime\": 1562484765.529141, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.529118}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9077176034450531, \"sum\": 0.9077176034450531, \"min\": 0.9077176034450531}}, \"EndTime\": 1562484765.529204, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.529187}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2055931541323661, \"sum\": 1.2055931541323661, \"min\": 1.2055931541323661}}, \"EndTime\": 1562484765.52927, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.529252}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2532026875019073, \"sum\": 1.2532026875019073, \"min\": 1.2532026875019073}}, \"EndTime\": 1562484765.529329, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.529311}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2394830894470215, \"sum\": 1.2394830894470215, \"min\": 1.2394830894470215}}, \"EndTime\": 1562484765.529382, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.529366}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.248119444847107, \"sum\": 1.248119444847107, \"min\": 1.248119444847107}}, \"EndTime\": 1562484765.529434, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.529419}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #quality_metric: host=algo-1, epoch=6, train mse_objective <loss>=0.139621556699\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=mse_objective, value=0.0950994444266\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}, \"Total Records Seen\": {\"count\": 1, \"max\": 7252, \"sum\": 7252.0, \"min\": 7252}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1562484765.532112, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1562484765.373114}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5618.86132918 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:45.664] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 132, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12645979315042497, \"sum\": 0.12645979315042497, \"min\": 0.12645979315042497}}, \"EndTime\": 1562484765.664995, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.664902}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15493205934762955, \"sum\": 0.15493205934762955, \"min\": 0.15493205934762955}}, \"EndTime\": 1562484765.665093, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665071}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1157967808842659, \"sum\": 0.1157967808842659, \"min\": 0.1157967808842659}}, \"EndTime\": 1562484765.665161, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665142}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.16790670931339263, \"sum\": 0.16790670931339263, \"min\": 0.16790670931339263}}, \"EndTime\": 1562484765.665224, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665204}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11886919006705284, \"sum\": 0.11886919006705284, \"min\": 0.11886919006705284}}, \"EndTime\": 1562484765.66529, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665272}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08106674302369356, \"sum\": 0.08106674302369356, \"min\": 0.08106674302369356}}, \"EndTime\": 1562484765.665352, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665336}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10413287341594696, \"sum\": 0.10413287341594696, \"min\": 0.10413287341594696}}, \"EndTime\": 1562484765.665407, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665391}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08304998889565468, \"sum\": 0.08304998889565468, \"min\": 0.08304998889565468}}, \"EndTime\": 1562484765.665463, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665447}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1589327162504196, \"sum\": 0.1589327162504196, \"min\": 0.1589327162504196}}, \"EndTime\": 1562484765.665521, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665505}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12609866693615912, \"sum\": 0.12609866693615912, \"min\": 0.12609866693615912}}, \"EndTime\": 1562484765.66558, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665564}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13756206452846528, \"sum\": 0.13756206452846528, \"min\": 0.13756206452846528}}, \"EndTime\": 1562484765.665641, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665624}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14093661934137344, \"sum\": 0.14093661934137344, \"min\": 0.14093661934137344}}, \"EndTime\": 1562484765.665706, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665687}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08697260513901711, \"sum\": 0.08697260513901711, \"min\": 0.08697260513901711}}, \"EndTime\": 1562484765.665771, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665753}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12942427814006804, \"sum\": 0.12942427814006804, \"min\": 0.12942427814006804}}, \"EndTime\": 1562484765.665837, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665818}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08567168459296226, \"sum\": 0.08567168459296226, \"min\": 0.08567168459296226}}, \"EndTime\": 1562484765.6659, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665883}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09467976689338684, \"sum\": 0.09467976689338684, \"min\": 0.09467976689338684}}, \"EndTime\": 1562484765.665963, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.665945}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13573713168501855, \"sum\": 0.13573713168501855, \"min\": 0.13573713168501855}}, \"EndTime\": 1562484765.66602, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666004}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13750334098935127, \"sum\": 0.13750334098935127, \"min\": 0.13750334098935127}}, \"EndTime\": 1562484765.666082, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666065}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13280532874166964, \"sum\": 0.13280532874166964, \"min\": 0.13280532874166964}}, \"EndTime\": 1562484765.666144, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666127}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1454276766628027, \"sum\": 0.1454276766628027, \"min\": 0.1454276766628027}}, \"EndTime\": 1562484765.666205, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666188}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.6778522169589997, \"sum\": 0.6778522169589997, \"min\": 0.6778522169589997}}, \"EndTime\": 1562484765.666263, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666246}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.686518942117691, \"sum\": 1.686518942117691, \"min\": 1.686518942117691}}, \"EndTime\": 1562484765.66632, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666303}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8149695143103599, \"sum\": 0.8149695143103599, \"min\": 0.8149695143103599}}, \"EndTime\": 1562484765.666378, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666361}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 2.1888034823536873, \"sum\": 2.1888034823536873, \"min\": 2.1888034823536873}}, \"EndTime\": 1562484765.666436, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.66642}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9092730045318603, \"sum\": 0.9092730045318603, \"min\": 0.9092730045318603}}, \"EndTime\": 1562484765.666493, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666477}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9110241901874542, \"sum\": 0.9110241901874542, \"min\": 0.9110241901874542}}, \"EndTime\": 1562484765.666548, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666533}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9129478698968887, \"sum\": 0.9129478698968887, \"min\": 0.9129478698968887}}, \"EndTime\": 1562484765.666605, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666589}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9114031887054443, \"sum\": 0.9114031887054443, \"min\": 0.9114031887054443}}, \"EndTime\": 1562484765.666663, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666647}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.129885932803154, \"sum\": 1.129885932803154, \"min\": 1.129885932803154}}, \"EndTime\": 1562484765.666719, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666703}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1387773391604423, \"sum\": 1.1387773391604423, \"min\": 1.1387773391604423}}, \"EndTime\": 1562484765.666777, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666761}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1263407316803933, \"sum\": 1.1263407316803933, \"min\": 1.1263407316803933}}, \"EndTime\": 1562484765.666832, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666818}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1331980621814728, \"sum\": 1.1331980621814728, \"min\": 1.1331980621814728}}, \"EndTime\": 1562484765.66688, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.666867}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #quality_metric: host=algo-1, epoch=7, train mse_objective <loss>=0.12645979315\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=mse_objective, value=0.0810667430237\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 82, \"sum\": 82.0, \"min\": 82}, \"Total Records Seen\": {\"count\": 1, \"max\": 8146, \"sum\": 8146.0, \"min\": 8146}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1562484765.670909, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1562484765.532367}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=6446.72914922 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:45.818] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 146, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11571909531950951, \"sum\": 0.11571909531950951, \"min\": 0.11571909531950951}}, \"EndTime\": 1562484765.818329, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818248}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14270324379205704, \"sum\": 0.14270324379205704, \"min\": 0.14270324379205704}}, \"EndTime\": 1562484765.818399, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818385}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10737087480723857, \"sum\": 0.10737087480723857, \"min\": 0.10737087480723857}}, \"EndTime\": 1562484765.818458, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818441}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.15385611325502396, \"sum\": 0.15385611325502396, \"min\": 0.15385611325502396}}, \"EndTime\": 1562484765.818516, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818501}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10156021669507026, \"sum\": 0.10156021669507026, \"min\": 0.10156021669507026}}, \"EndTime\": 1562484765.818571, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818554}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.07987530335783959, \"sum\": 0.07987530335783959, \"min\": 0.07987530335783959}}, \"EndTime\": 1562484765.81863, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818613}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09536284759640694, \"sum\": 0.09536284759640694, \"min\": 0.09536284759640694}}, \"EndTime\": 1562484765.81869, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818673}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.0822727832198143, \"sum\": 0.0822727832198143, \"min\": 0.0822727832198143}}, \"EndTime\": 1562484765.818751, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818733}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1464065656065941, \"sum\": 0.1464065656065941, \"min\": 0.1464065656065941}}, \"EndTime\": 1562484765.81881, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818793}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11645032435655595, \"sum\": 0.11645032435655595, \"min\": 0.11645032435655595}}, \"EndTime\": 1562484765.818871, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818853}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12556692987680435, \"sum\": 0.12556692987680435, \"min\": 0.12556692987680435}}, \"EndTime\": 1562484765.818933, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818916}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12824140429496766, \"sum\": 0.12824140429496766, \"min\": 0.12824140429496766}}, \"EndTime\": 1562484765.818994, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.818977}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.07853649973869324, \"sum\": 0.07853649973869324, \"min\": 0.07853649973869324}}, \"EndTime\": 1562484765.819062, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819045}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10952444076538086, \"sum\": 0.10952444076538086, \"min\": 0.10952444076538086}}, \"EndTime\": 1562484765.819119, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819103}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08475215539336205, \"sum\": 0.08475215539336205, \"min\": 0.08475215539336205}}, \"EndTime\": 1562484765.819179, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819161}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.0842167592048645, \"sum\": 0.0842167592048645, \"min\": 0.0842167592048645}}, \"EndTime\": 1562484765.819237, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819221}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13196578860282898, \"sum\": 0.13196578860282898, \"min\": 0.13196578860282898}}, \"EndTime\": 1562484765.819299, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819282}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13104190781712532, \"sum\": 0.13104190781712532, \"min\": 0.13104190781712532}}, \"EndTime\": 1562484765.819359, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819341}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12982297122478484, \"sum\": 0.12982297122478484, \"min\": 0.12982297122478484}}, \"EndTime\": 1562484765.81942, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819402}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1400017435848713, \"sum\": 0.1400017435848713, \"min\": 0.1400017435848713}}, \"EndTime\": 1562484765.81949, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819472}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.3870606112480164, \"sum\": 0.3870606112480164, \"min\": 0.3870606112480164}}, \"EndTime\": 1562484765.819552, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819535}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1837371587753296, \"sum\": 1.1837371587753296, \"min\": 1.1837371587753296}}, \"EndTime\": 1562484765.819611, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819594}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.555419003367424, \"sum\": 0.555419003367424, \"min\": 0.555419003367424}}, \"EndTime\": 1562484765.81967, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819652}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.7646804237365723, \"sum\": 1.7646804237365723, \"min\": 1.7646804237365723}}, \"EndTime\": 1562484765.819727, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819711}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9075506019592285, \"sum\": 0.9075506019592285, \"min\": 0.9075506019592285}}, \"EndTime\": 1562484765.819786, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819768}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9060317981243133, \"sum\": 0.9060317981243133, \"min\": 0.9060317981243133}}, \"EndTime\": 1562484765.81984, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819824}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9071548569202423, \"sum\": 0.9071548569202423, \"min\": 0.9071548569202423}}, \"EndTime\": 1562484765.819904, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819887}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9101401132345199, \"sum\": 0.9101401132345199, \"min\": 0.9101401132345199}}, \"EndTime\": 1562484765.819963, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.819945}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1694648265838623, \"sum\": 1.1694648265838623, \"min\": 1.1694648265838623}}, \"EndTime\": 1562484765.820022, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.820004}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2129713296890259, \"sum\": 1.2129713296890259, \"min\": 1.2129713296890259}}, \"EndTime\": 1562484765.820095, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.820073}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1926819705963134, \"sum\": 1.1926819705963134, \"min\": 1.1926819705963134}}, \"EndTime\": 1562484765.820168, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.820149}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2201606982946396, \"sum\": 1.2201606982946396, \"min\": 1.2201606982946396}}, \"EndTime\": 1562484765.820236, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.820217}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #quality_metric: host=algo-1, epoch=8, train mse_objective <loss>=0.11571909532\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=mse_objective, value=0.0785364997387\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Total Records Seen\": {\"count\": 1, \"max\": 9040, \"sum\": 9040.0, \"min\": 9040}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1562484765.822953, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1562484765.671203}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5885.91081915 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:45.985] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 162, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10731310039758682, \"sum\": 0.10731310039758682, \"min\": 0.10731310039758682}}, \"EndTime\": 1562484765.986056, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.985983}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13146523267030716, \"sum\": 0.13146523267030716, \"min\": 0.13146523267030716}}, \"EndTime\": 1562484765.986142, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986122}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10083228908479214, \"sum\": 0.10083228908479214, \"min\": 0.10083228908479214}}, \"EndTime\": 1562484765.986212, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986193}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14082373470067977, \"sum\": 0.14082373470067977, \"min\": 0.14082373470067977}}, \"EndTime\": 1562484765.986278, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.98626}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10555702984333039, \"sum\": 0.10555702984333039, \"min\": 0.10555702984333039}}, \"EndTime\": 1562484765.986346, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986328}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09189833514392376, \"sum\": 0.09189833514392376, \"min\": 0.09189833514392376}}, \"EndTime\": 1562484765.986419, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986399}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1097959354519844, \"sum\": 0.1097959354519844, \"min\": 0.1097959354519844}}, \"EndTime\": 1562484765.98648, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986463}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09473729677498341, \"sum\": 0.09473729677498341, \"min\": 0.09473729677498341}}, \"EndTime\": 1562484765.986543, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986525}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13499355286359788, \"sum\": 0.13499355286359788, \"min\": 0.13499355286359788}}, \"EndTime\": 1562484765.986615, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986596}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10895133048295974, \"sum\": 0.10895133048295974, \"min\": 0.10895133048295974}}, \"EndTime\": 1562484765.986676, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986658}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1154016137123108, \"sum\": 0.1154016137123108, \"min\": 0.1154016137123108}}, \"EndTime\": 1562484765.986737, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986719}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1179474513232708, \"sum\": 0.1179474513232708, \"min\": 0.1179474513232708}}, \"EndTime\": 1562484765.986796, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986779}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08753092169761657, \"sum\": 0.08753092169761657, \"min\": 0.08753092169761657}}, \"EndTime\": 1562484765.986855, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986838}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11611376285552978, \"sum\": 0.11611376285552978, \"min\": 0.11611376285552978}}, \"EndTime\": 1562484765.986915, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986899}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09956855341792106, \"sum\": 0.09956855341792106, \"min\": 0.09956855341792106}}, \"EndTime\": 1562484765.986977, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.986959}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.0807610397785902, \"sum\": 0.0807610397785902, \"min\": 0.0807610397785902}}, \"EndTime\": 1562484765.987046, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987028}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12873519852757453, \"sum\": 0.12873519852757453, \"min\": 0.12873519852757453}}, \"EndTime\": 1562484765.987106, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987089}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12546441301703454, \"sum\": 0.12546441301703454, \"min\": 0.12546441301703454}}, \"EndTime\": 1562484765.987166, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987148}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12734513960778712, \"sum\": 0.12734513960778712, \"min\": 0.12734513960778712}}, \"EndTime\": 1562484765.987234, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987216}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.13492212064564227, \"sum\": 0.13492212064564227, \"min\": 0.13492212064564227}}, \"EndTime\": 1562484765.987296, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987279}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.22876151233911515, \"sum\": 0.22876151233911515, \"min\": 0.22876151233911515}}, \"EndTime\": 1562484765.987354, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987339}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.8709348011016845, \"sum\": 0.8709348011016845, \"min\": 0.8709348011016845}}, \"EndTime\": 1562484765.987412, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987396}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.494880268573761, \"sum\": 0.494880268573761, \"min\": 0.494880268573761}}, \"EndTime\": 1562484765.987466, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987454}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.443442153930664, \"sum\": 1.443442153930664, \"min\": 1.443442153930664}}, \"EndTime\": 1562484765.987507, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987493}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.906796236038208, \"sum\": 0.906796236038208, \"min\": 0.906796236038208}}, \"EndTime\": 1562484765.987564, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987548}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9070095723867416, \"sum\": 0.9070095723867416, \"min\": 0.9070095723867416}}, \"EndTime\": 1562484765.987617, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987607}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9043300151824951, \"sum\": 0.9043300151824951, \"min\": 0.9043300151824951}}, \"EndTime\": 1562484765.987672, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987655}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9076823514699935, \"sum\": 0.9076823514699935, \"min\": 0.9076823514699935}}, \"EndTime\": 1562484765.987738, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987721}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1740852046012877, \"sum\": 1.1740852046012877, \"min\": 1.1740852046012877}}, \"EndTime\": 1562484765.987801, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987782}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1997476106882095, \"sum\": 1.1997476106882095, \"min\": 1.1997476106882095}}, \"EndTime\": 1562484765.987872, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987853}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1810902231931686, \"sum\": 1.1810902231931686, \"min\": 1.1810902231931686}}, \"EndTime\": 1562484765.987933, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987915}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1987422376871109, \"sum\": 1.1987422376871109, \"min\": 1.1987422376871109}}, \"EndTime\": 1562484765.988002, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.987984}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #quality_metric: host=algo-1, epoch=9, train mse_objective <loss>=0.107313100398\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=mse_objective, value=0.0807610397786\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Total Records Seen\": {\"count\": 1, \"max\": 9934, \"sum\": 9934.0, \"min\": 9934}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1562484765.989953, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1562484765.823245}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:45 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5358.96850539 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:46.149] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 159, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10067458808422089, \"sum\": 0.10067458808422089, \"min\": 0.10067458808422089}}, \"EndTime\": 1562484766.149891, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.149797}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.121889977902174, \"sum\": 0.121889977902174, \"min\": 0.121889977902174}}, \"EndTime\": 1562484766.149979, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.149958}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09577499970793724, \"sum\": 0.09577499970793724, \"min\": 0.09577499970793724}}, \"EndTime\": 1562484766.150046, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150027}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12949184477329254, \"sum\": 0.12949184477329254, \"min\": 0.12949184477329254}}, \"EndTime\": 1562484766.15011, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150092}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08900651410222053, \"sum\": 0.08900651410222053, \"min\": 0.08900651410222053}}, \"EndTime\": 1562484766.150174, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150155}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08370759248733521, \"sum\": 0.08370759248733521, \"min\": 0.08370759248733521}}, \"EndTime\": 1562484766.150234, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150217}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08831955432891846, \"sum\": 0.08831955432891846, \"min\": 0.08831955432891846}}, \"EndTime\": 1562484766.150292, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150275}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08577363818883896, \"sum\": 0.08577363818883896, \"min\": 0.08577363818883896}}, \"EndTime\": 1562484766.150354, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150336}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12515624940395356, \"sum\": 0.12515624940395356, \"min\": 0.12515624940395356}}, \"EndTime\": 1562484766.150413, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150396}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10305721610784531, \"sum\": 0.10305721610784531, \"min\": 0.10305721610784531}}, \"EndTime\": 1562484766.150472, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150456}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10715850412845612, \"sum\": 0.10715850412845612, \"min\": 0.10715850412845612}}, \"EndTime\": 1562484766.150532, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150515}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10983078435063362, \"sum\": 0.10983078435063362, \"min\": 0.10983078435063362}}, \"EndTime\": 1562484766.15059, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150573}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08040179237723351, \"sum\": 0.08040179237723351, \"min\": 0.08040179237723351}}, \"EndTime\": 1562484766.150649, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150633}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.0949066849052906, \"sum\": 0.0949066849052906, \"min\": 0.0949066849052906}}, \"EndTime\": 1562484766.150707, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.15069}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08594655752182007, \"sum\": 0.08594655752182007, \"min\": 0.08594655752182007}}, \"EndTime\": 1562484766.150771, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150749}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08057063948363066, \"sum\": 0.08057063948363066, \"min\": 0.08057063948363066}}, \"EndTime\": 1562484766.150829, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150812}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12533224187791348, \"sum\": 0.12533224187791348, \"min\": 0.12533224187791348}}, \"EndTime\": 1562484766.150888, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150872}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1204619561880827, \"sum\": 0.1204619561880827, \"min\": 0.1204619561880827}}, \"EndTime\": 1562484766.15094, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150924}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1245812338590622, \"sum\": 0.1245812338590622, \"min\": 0.1245812338590622}}, \"EndTime\": 1562484766.151, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.150983}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12984287828207017, \"sum\": 0.12984287828207017, \"min\": 0.12984287828207017}}, \"EndTime\": 1562484766.151045, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151031}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.17135785281658172, \"sum\": 0.17135785281658172, \"min\": 0.17135785281658172}}, \"EndTime\": 1562484766.151108, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151091}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.5066420841217041, \"sum\": 0.5066420841217041, \"min\": 0.5066420841217041}}, \"EndTime\": 1562484766.15116, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151147}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.3685819149017334, \"sum\": 0.3685819149017334, \"min\": 0.3685819149017334}}, \"EndTime\": 1562484766.151211, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151198}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.788664967417717, \"sum\": 0.788664967417717, \"min\": 0.788664967417717}}, \"EndTime\": 1562484766.151264, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151249}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9072187310457229, \"sum\": 0.9072187310457229, \"min\": 0.9072187310457229}}, \"EndTime\": 1562484766.15132, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151304}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9088742113113404, \"sum\": 0.9088742113113404, \"min\": 0.9088742113113404}}, \"EndTime\": 1562484766.151374, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151359}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9067058235406875, \"sum\": 0.9067058235406875, \"min\": 0.9067058235406875}}, \"EndTime\": 1562484766.151431, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151415}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9081050777435302, \"sum\": 0.9081050777435302, \"min\": 0.9081050777435302}}, \"EndTime\": 1562484766.151488, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151472}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1657990574836732, \"sum\": 1.1657990574836732, \"min\": 1.1657990574836732}}, \"EndTime\": 1562484766.151535, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.15152}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.206693993806839, \"sum\": 1.206693993806839, \"min\": 1.206693993806839}}, \"EndTime\": 1562484766.151593, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151577}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1776857960224152, \"sum\": 1.1776857960224152, \"min\": 1.1776857960224152}}, \"EndTime\": 1562484766.151647, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.151631}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2068894273042678, \"sum\": 1.2068894273042678, \"min\": 1.2068894273042678}}, \"EndTime\": 1562484766.151706, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484766.15169}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #quality_metric: host=algo-1, epoch=10, train mse_objective <loss>=0.100674588084\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=mse_objective, value=0.0804017923772\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 109, \"sum\": 109.0, \"min\": 109}, \"Total Records Seen\": {\"count\": 1, \"max\": 10828, \"sum\": 10828.0, \"min\": 10828}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1562484766.153597, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1562484765.990184}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5466.7555645 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:46.324] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 170, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09536521576344967, \"sum\": 0.09536521576344967, \"min\": 0.09536521576344967}}, \"EndTime\": 1562484766.324241, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.32418}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11400932908058166, \"sum\": 0.11400932908058166, \"min\": 0.11400932908058166}}, \"EndTime\": 1562484766.324302, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.32429}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09177128598093987, \"sum\": 0.09177128598093987, \"min\": 0.09177128598093987}}, \"EndTime\": 1562484766.324335, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324327}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11998460203409195, \"sum\": 0.11998460203409195, \"min\": 0.11998460203409195}}, \"EndTime\": 1562484766.324365, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324357}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08934007659554481, \"sum\": 0.08934007659554481, \"min\": 0.08934007659554481}}, \"EndTime\": 1562484766.324393, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324386}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08981431126594544, \"sum\": 0.08981431126594544, \"min\": 0.08981431126594544}}, \"EndTime\": 1562484766.32442, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324413}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09248005777597428, \"sum\": 0.09248005777597428, \"min\": 0.09248005777597428}}, \"EndTime\": 1562484766.324448, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324441}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09239118263125419, \"sum\": 0.09239118263125419, \"min\": 0.09239118263125419}}, \"EndTime\": 1562484766.324475, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324468}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11695530295372009, \"sum\": 0.11695530295372009, \"min\": 0.11695530295372009}}, \"EndTime\": 1562484766.324501, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324494}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09830029778182507, \"sum\": 0.09830029778182507, \"min\": 0.09830029778182507}}, \"EndTime\": 1562484766.324526, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.32452}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10054232642054557, \"sum\": 0.10054232642054557, \"min\": 0.10054232642054557}}, \"EndTime\": 1562484766.324552, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324545}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10339723110198974, \"sum\": 0.10339723110198974, \"min\": 0.10339723110198974}}, \"EndTime\": 1562484766.324577, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324571}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08634996384382249, \"sum\": 0.08634996384382249, \"min\": 0.08634996384382249}}, \"EndTime\": 1562484766.324603, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324596}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09874211043119431, \"sum\": 0.09874211043119431, \"min\": 0.09874211043119431}}, \"EndTime\": 1562484766.324628, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324622}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09031458646059036, \"sum\": 0.09031458646059036, \"min\": 0.09031458646059036}}, \"EndTime\": 1562484766.324653, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324647}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08257757037878037, \"sum\": 0.08257757037878037, \"min\": 0.08257757037878037}}, \"EndTime\": 1562484766.324679, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324672}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1219110630452633, \"sum\": 0.1219110630452633, \"min\": 0.1219110630452633}}, \"EndTime\": 1562484766.324704, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324697}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11636855199933052, \"sum\": 0.11636855199933052, \"min\": 0.11636855199933052}}, \"EndTime\": 1562484766.324729, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324723}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12160709701478481, \"sum\": 0.12160709701478481, \"min\": 0.12160709701478481}}, \"EndTime\": 1562484766.324755, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324748}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12520207434892655, \"sum\": 0.12520207434892655, \"min\": 0.12520207434892655}}, \"EndTime\": 1562484766.324834, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324817}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.14108328610658646, \"sum\": 0.14108328610658646, \"min\": 0.14108328610658646}}, \"EndTime\": 1562484766.324887, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324874}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.27066152930259707, \"sum\": 0.27066152930259707, \"min\": 0.27066152930259707}}, \"EndTime\": 1562484766.324943, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324928}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.2939066654443741, \"sum\": 0.2939066654443741, \"min\": 0.2939066654443741}}, \"EndTime\": 1562484766.325, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.324983}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.32989092528820035, \"sum\": 0.32989092528820035, \"min\": 0.32989092528820035}}, \"EndTime\": 1562484766.325055, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325041}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9075084429979324, \"sum\": 0.9075084429979324, \"min\": 0.9075084429979324}}, \"EndTime\": 1562484766.32511, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325093}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9080873847007751, \"sum\": 0.9080873847007751, \"min\": 0.9080873847007751}}, \"EndTime\": 1562484766.325165, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325149}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9084514033794403, \"sum\": 0.9084514033794403, \"min\": 0.9084514033794403}}, \"EndTime\": 1562484766.32522, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325205}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9089078664779663, \"sum\": 0.9089078664779663, \"min\": 0.9089078664779663}}, \"EndTime\": 1562484766.325284, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325267}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1813471466302872, \"sum\": 1.1813471466302872, \"min\": 1.1813471466302872}}, \"EndTime\": 1562484766.325344, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325328}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.223636104464531, \"sum\": 1.223636104464531, \"min\": 1.223636104464531}}, \"EndTime\": 1562484766.325402, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325386}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1960245263576508, \"sum\": 1.1960245263576508, \"min\": 1.1960245263576508}}, \"EndTime\": 1562484766.325458, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325442}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2222626084089279, \"sum\": 1.2222626084089279, \"min\": 1.2222626084089279}}, \"EndTime\": 1562484766.325512, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.325497}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #quality_metric: host=algo-1, epoch=11, train mse_objective <loss>=0.0953652157634\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=mse_objective, value=0.0825775703788\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 118, \"sum\": 118.0, \"min\": 118}, \"Total Records Seen\": {\"count\": 1, \"max\": 11722, \"sum\": 11722.0, \"min\": 11722}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1562484766.328334, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1562484766.153847}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=5120.21533344 records/second\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:46.523] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 194, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09106245391070843, \"sum\": 0.09106245391070843, \"min\": 0.09106245391070843}}, \"EndTime\": 1562484766.523593, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.523502}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.10754807263612748, \"sum\": 0.10754807263612748, \"min\": 0.10754807263612748}}, \"EndTime\": 1562484766.523688, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.523668}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08850820362567902, \"sum\": 0.08850820362567902, \"min\": 0.08850820362567902}}, \"EndTime\": 1562484766.523748, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.523731}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11209395349025726, \"sum\": 0.11209395349025726, \"min\": 0.11209395349025726}}, \"EndTime\": 1562484766.523803, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.523786}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08577178739011287, \"sum\": 0.08577178739011287, \"min\": 0.08577178739011287}}, \"EndTime\": 1562484766.523862, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.523845}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08871769890189171, \"sum\": 0.08871769890189171, \"min\": 0.08871769890189171}}, \"EndTime\": 1562484766.523921, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.523904}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08382674157619477, \"sum\": 0.08382674157619477, \"min\": 0.08382674157619477}}, \"EndTime\": 1562484766.523979, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.523963}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09086426958441735, \"sum\": 0.09086426958441735, \"min\": 0.09086426958441735}}, \"EndTime\": 1562484766.524038, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524021}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11018767714500427, \"sum\": 0.11018767714500427, \"min\": 0.11018767714500427}}, \"EndTime\": 1562484766.524094, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524078}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09435680352151393, \"sum\": 0.09435680352151393, \"min\": 0.09435680352151393}}, \"EndTime\": 1562484766.524154, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524137}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09519730493426323, \"sum\": 0.09519730493426323, \"min\": 0.09519730493426323}}, \"EndTime\": 1562484766.524213, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524196}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09820068523287773, \"sum\": 0.09820068523287773, \"min\": 0.09820068523287773}}, \"EndTime\": 1562484766.52427, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524254}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08285108484327793, \"sum\": 0.08285108484327793, \"min\": 0.08285108484327793}}, \"EndTime\": 1562484766.524329, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524312}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.09313887357711792, \"sum\": 0.09313887357711792, \"min\": 0.09313887357711792}}, \"EndTime\": 1562484766.524385, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524369}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08510140746831894, \"sum\": 0.08510140746831894, \"min\": 0.08510140746831894}}, \"EndTime\": 1562484766.524439, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524423}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.08802879735827446, \"sum\": 0.08802879735827446, \"min\": 0.08802879735827446}}, \"EndTime\": 1562484766.524499, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524481}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.1188492126762867, \"sum\": 0.1188492126762867, \"min\": 0.1188492126762867}}, \"EndTime\": 1562484766.524559, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524541}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11335506990551948, \"sum\": 0.11335506990551948, \"min\": 0.11335506990551948}}, \"EndTime\": 1562484766.524617, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524601}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.11880467124283314, \"sum\": 0.11880467124283314, \"min\": 0.11880467124283314}}, \"EndTime\": 1562484766.524674, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524657}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12137967512011529, \"sum\": 0.12137967512011529, \"min\": 0.12137967512011529}}, \"EndTime\": 1562484766.524733, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524717}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.12953216403722764, \"sum\": 0.12953216403722764, \"min\": 0.12953216403722764}}, \"EndTime\": 1562484766.524821, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524803}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.18809422016143798, \"sum\": 0.18809422016143798, \"min\": 0.18809422016143798}}, \"EndTime\": 1562484766.524881, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524865}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.250748039484024, \"sum\": 0.250748039484024, \"min\": 0.250748039484024}}, \"EndTime\": 1562484766.524934, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.52492}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.18021456003189087, \"sum\": 0.18021456003189087, \"min\": 0.18021456003189087}}, \"EndTime\": 1562484766.524994, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.524977}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9069296723604202, \"sum\": 0.9069296723604202, \"min\": 0.9069296723604202}}, \"EndTime\": 1562484766.525054, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.525037}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.907143446803093, \"sum\": 0.907143446803093, \"min\": 0.907143446803093}}, \"EndTime\": 1562484766.525111, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.525095}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9073335546255111, \"sum\": 0.9073335546255111, \"min\": 0.9073335546255111}}, \"EndTime\": 1562484766.52517, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.525154}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9088807946443558, \"sum\": 0.9088807946443558, \"min\": 0.9088807946443558}}, \"EndTime\": 1562484766.525226, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.52521}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.1732341599464418, \"sum\": 1.1732341599464418, \"min\": 1.1732341599464418}}, \"EndTime\": 1562484766.525283, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.525266}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2113650739192963, \"sum\": 1.2113650739192963, \"min\": 1.2113650739192963}}, \"EndTime\": 1562484766.525341, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.525324}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.182155230641365, \"sum\": 1.182155230641365, \"min\": 1.182155230641365}}, \"EndTime\": 1562484766.525399, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.525383}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.2104032212495803, \"sum\": 1.2104032212495803, \"min\": 1.2104032212495803}}, \"EndTime\": 1562484766.525455, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.52544}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #quality_metric: host=algo-1, epoch=12, train mse_objective <loss>=0.0910624539107\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=mse_objective, value=0.0828510848433\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Total Batches Seen\": {\"count\": 1, \"max\": 127, \"sum\": 127.0, \"min\": 127}, \"Total Records Seen\": {\"count\": 1, \"max\": 12616, \"sum\": 12616.0, \"min\": 12616}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 894, \"sum\": 894.0, \"min\": 894}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1562484766.529051, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1562484766.328599}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #throughput_metric: host=algo-1, train throughput=4456.91818243 records/second\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 WARNING 139741542360896] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 WARNING 139741542360896] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:46.530] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 0, \"num_examples\": 1, \"num_bytes\": 9600}\u001b[0m\n",
      "\u001b[31m[2019-07-07 07:32:46.548] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 15, \"num_examples\": 9, \"num_bytes\": 85824}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #train_score (algo-1) : ('mse_objective', 27.107926746342805)\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #train_score (algo-1) : ('mse', 27.107926746342805)\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #train_score (algo-1) : ('absolute_loss', 4.345149456254588)\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #quality_metric: host=algo-1, train mse_objective <loss>=27.1079267463\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #quality_metric: host=algo-1, train mse <loss>=27.1079267463\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] #quality_metric: host=algo-1, train absolute_loss <loss>=4.34514945625\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] Best model found for hyperparameters: {\"lr_scheduler_step\": 10, \"wd\": 0.01, \"optimizer\": \"adam\", \"lr_scheduler_factor\": 0.99, \"l1\": 0.0, \"learning_rate\": 0.1, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] Saved checkpoint to \"/tmp/tmp23Bw16/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[31m[07/07/2019 07:32:46 INFO 139741542360896] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 2350.761890411377, \"sum\": 2350.761890411377, \"min\": 2350.761890411377}, \"finalize.time\": {\"count\": 1, \"max\": 20.35689353942871, \"sum\": 20.35689353942871, \"min\": 20.35689353942871}, \"initialize.time\": {\"count\": 1, \"max\": 139.73093032836914, \"sum\": 139.73093032836914, \"min\": 139.73093032836914}, \"check_early_stopping.time\": {\"count\": 13, \"max\": 1.0919570922851562, \"sum\": 9.153366088867188, \"min\": 0.1671314239501953}, \"setuptime\": {\"count\": 1, \"max\": 22.933006286621094, \"sum\": 22.933006286621094, \"min\": 22.933006286621094}, \"update.time\": {\"count\": 13, \"max\": 200.1481056213379, \"sum\": 2101.9809246063232, \"min\": 138.36097717285156}, \"epochs\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1562484766.558574, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1562484764.280567}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-07-07 07:32:54 Uploading - Uploading generated training model\n",
      "2019-07-07 07:32:54 Completed - Training job completed\n",
      "Billable seconds: 42\n",
      "-------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "linear.set_hyperparameters(feature_dim=13,\n",
    "                           predictor_type='regressor',\n",
    "                           mini_batch_size=100,\n",
    "                           normalize_data=False)\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "linear_predictor = linear.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.c4.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'score': 19.28443145751953}]}\n"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "linear.fit({'train': s3_train_data})\n",
    "linear_predictor = linear.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.c4.xlarge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_code</th>\n",
       "      <th>material</th>\n",
       "      <th>box_code</th>\n",
       "      <th>bursting_factor</th>\n",
       "      <th>flute_type</th>\n",
       "      <th>inner_height_mm</th>\n",
       "      <th>height_inch</th>\n",
       "      <th>inner_height</th>\n",
       "      <th>length_inch</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>quantity</th>\n",
       "      <th>status</th>\n",
       "      <th>company_id</th>\n",
       "      <th>per_unit</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>646.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>687.00</td>\n",
       "      <td>7.9</td>\n",
       "      <td>46</td>\n",
       "      <td>795</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.710000</td>\n",
       "      <td>19.284431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>646.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>687.00</td>\n",
       "      <td>7.9</td>\n",
       "      <td>46</td>\n",
       "      <td>12490</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>18.713291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>67.455147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30</td>\n",
       "      <td>2165</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.297081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30</td>\n",
       "      <td>315</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.387428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29</td>\n",
       "      <td>825</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67.229947</td>\n",
       "      <td>67.415344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>14.219876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1998</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>14.140439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>14.127779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>990</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.345800</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>6.784356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>6.692259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.677960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>6.705553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.695800</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>3.1</td>\n",
       "      <td>660.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41.210000</td>\n",
       "      <td>29.573015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>13000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.349485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.837848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36</td>\n",
       "      <td>28925</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>5.797731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>755</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>6.765324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>6.069651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.447648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38</td>\n",
       "      <td>26174</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>5.901951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35</td>\n",
       "      <td>28550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.639527</td>\n",
       "      <td>5.831109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>2950</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>6.658129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.629801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>3040</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.435919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.707938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.851836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.431674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.571197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.998345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.919989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.462996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22</td>\n",
       "      <td>44975</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.960000</td>\n",
       "      <td>4.204218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>5.643124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.096018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>4.301453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.119291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>4.910580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.188114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.034620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.790438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>11000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.985784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.882535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.517407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>4.790438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.301453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>9700</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.110668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.437872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>5.398943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.546257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.486708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sku_code  material  box_code  bursting_factor  flute_type  \\\n",
       "0           1         1        15                5           1   \n",
       "1           1         1        15                5           1   \n",
       "2          21         0        16                0           2   \n",
       "3          22         0         0                0           2   \n",
       "4          22         0         0                0           2   \n",
       "5          21         0        16                0           2   \n",
       "6           5         0         1                1           0   \n",
       "7           5         0         1                1           0   \n",
       "8           5         0         1                1           0   \n",
       "9           5         0         1                1           0   \n",
       "10          5         0         1                1           0   \n",
       "11          5         0         1                1           0   \n",
       "12          5         0         1                1           0   \n",
       "13          4         0         2                1           0   \n",
       "14          4         0         2                1           0   \n",
       "15          4         0         2                1           0   \n",
       "16          4         0         2                1           0   \n",
       "17          4         0         2                1           0   \n",
       "18          4         0         2                1           0   \n",
       "19          4         0         2                1           0   \n",
       "20          3         1         3                4           0   \n",
       "21         13         1         6                3           0   \n",
       "22         13         1         6                3           0   \n",
       "23         13         1         6                3           0   \n",
       "24         13         1         6                3           0   \n",
       "25         13         1         6                3           0   \n",
       "26         13         1         6                3           0   \n",
       "27         13         1         6                3           0   \n",
       "28         13         1         6                3           0   \n",
       "29         13         1         6                3           0   \n",
       "..        ...       ...       ...              ...         ...   \n",
       "864         7         1         7                3           0   \n",
       "865         7         1         7                3           0   \n",
       "866         7         1         7                3           0   \n",
       "867         7         1         7                3           0   \n",
       "868         7         1         7                3           0   \n",
       "869         7         1         7                3           0   \n",
       "870         7         1         7                3           0   \n",
       "871         7         1         7                3           0   \n",
       "872         7         1         7                3           0   \n",
       "873         7         1         7                3           0   \n",
       "874         7         1         7                3           0   \n",
       "875         7         1         7                3           0   \n",
       "876         7         1         7                3           0   \n",
       "877         7         1         7                3           0   \n",
       "878         7         1         7                3           0   \n",
       "879         7         1         7                3           0   \n",
       "880         7         1         7                3           0   \n",
       "881         7         1         7                3           0   \n",
       "882         7         1         7                3           0   \n",
       "883         7         1         7                3           0   \n",
       "884         7         1         7                3           0   \n",
       "885         7         1         7                3           0   \n",
       "886         7         1         7                3           0   \n",
       "887         7         1         7                3           0   \n",
       "888         7         1         7                3           0   \n",
       "889         7         1         7                3           0   \n",
       "890         7         1         7                3           0   \n",
       "891         7         1         7                3           0   \n",
       "892         7         1         7                3           0   \n",
       "893         7         1         7                3           0   \n",
       "\n",
       "     inner_height_mm  height_inch  inner_height  length_inch  updated_at  \\\n",
       "0             646.00          3.9        687.00          7.9          46   \n",
       "1             646.00          3.9        687.00          7.9          46   \n",
       "2             300.00         11.8        730.00         28.7          29   \n",
       "3             300.00         11.8        730.00         28.7          30   \n",
       "4             300.00         11.8        730.00         28.7          30   \n",
       "5             300.00         11.8        730.00         28.7          29   \n",
       "6             101.14          4.1        306.88         12.2          44   \n",
       "7             101.14          4.1        306.88         12.2          44   \n",
       "8             101.14          4.1        306.88         12.2          44   \n",
       "9             101.14          4.1        306.88         12.2          44   \n",
       "10            101.14          4.1        306.88         12.2          44   \n",
       "11            101.14          4.1        306.88         12.2          44   \n",
       "12            101.14          4.1        306.88         12.2          44   \n",
       "13             90.98          3.7        197.66          7.9          45   \n",
       "14             90.98          3.7        197.66          7.9          45   \n",
       "15             90.98          3.7        197.66          7.9          45   \n",
       "16             90.98          3.7        197.66          7.9          45   \n",
       "17             90.98          3.7        197.66          7.9          45   \n",
       "18             90.98          3.7        197.66          7.9          45   \n",
       "19             90.98          3.7        197.66          7.9          45   \n",
       "20             80.00          3.1        660.00         26.0          47   \n",
       "21             90.00          3.0        220.00          8.0          51   \n",
       "22             90.00          3.0        220.00          8.0          51   \n",
       "23             90.00          3.0        220.00          8.0          36   \n",
       "24             90.00          3.0        220.00          8.0          51   \n",
       "25             90.00          3.0        220.00          8.0          51   \n",
       "26             90.00          3.0        220.00          8.0          38   \n",
       "27             90.00          3.0        220.00          8.0          38   \n",
       "28             90.00          3.0        220.00          8.0          35   \n",
       "29             90.00          3.0        220.00          8.0          51   \n",
       "..               ...          ...           ...          ...         ...   \n",
       "864           120.00          4.0        250.00          9.0          52   \n",
       "865           120.00          4.0        250.00          9.0          52   \n",
       "866           120.00          4.0        250.00          9.0          52   \n",
       "867           120.00          4.0        250.00          9.0          52   \n",
       "868           120.00          4.0        250.00          9.0          52   \n",
       "869           120.00          4.0        250.00          9.0          52   \n",
       "870           120.00          4.0        250.00          9.0          52   \n",
       "871           120.00          4.0        250.00          9.0          52   \n",
       "872           120.00          4.0        250.00          9.0          52   \n",
       "873           120.00          4.0        250.00          9.0          52   \n",
       "874           120.00          4.0        250.00          9.0          22   \n",
       "875           120.00          4.0        250.00          9.0          52   \n",
       "876           120.00          4.0        250.00          9.0          52   \n",
       "877           120.00          4.0        250.00          9.0          52   \n",
       "878           120.00          4.0        250.00          9.0          52   \n",
       "879           120.00          4.0        250.00          9.0          52   \n",
       "880           120.00          4.0        250.00          9.0          52   \n",
       "881           120.00          4.0        250.00          9.0          52   \n",
       "882           120.00          4.0        250.00          9.0          52   \n",
       "883           120.00          4.0        250.00          9.0          52   \n",
       "884           120.00          4.0        250.00          9.0          52   \n",
       "885           120.00          4.0        250.00          9.0          52   \n",
       "886           120.00          4.0        250.00          9.0          52   \n",
       "887           120.00          4.0        250.00          9.0          52   \n",
       "888           120.00          4.0        250.00          9.0          52   \n",
       "889           120.00          4.0        250.00          9.0          52   \n",
       "890           120.00          4.0        250.00          9.0          52   \n",
       "891           120.00          4.0        250.00          9.0          52   \n",
       "892           120.00          4.0        250.00          9.0          52   \n",
       "893           120.00          4.0        250.00          9.0          52   \n",
       "\n",
       "     quantity  status  company_id   per_unit  Predicted  \n",
       "0         795       3           0   6.710000  19.284431  \n",
       "1       12490       3           0   7.100000  18.713291  \n",
       "2          10       3           0  63.430000  67.455147  \n",
       "3        2165       3           2  67.000000  62.297081  \n",
       "4         315       3           2  67.000000  62.387428  \n",
       "5         825       3           0  67.229947  67.415344  \n",
       "6        1000       4           0   6.930000  14.219876  \n",
       "7        1998       3           0   7.340000  14.140439  \n",
       "8        1000       1           0   6.930000  14.127779  \n",
       "9        1000       3           0   7.860000  14.189178  \n",
       "10       1000       3           0   7.860000  14.189178  \n",
       "11        990       3           0   7.860000  14.189666  \n",
       "12       1000       3           0   7.345800  14.189178  \n",
       "13       1000       4           0   4.430000   6.784356  \n",
       "14       1000       3           0   5.020000   6.753656  \n",
       "15       1000       1           0   4.430000   6.692259  \n",
       "16       2550       3           0   5.020000   6.677960  \n",
       "17       1985       3           0   4.680000   6.705553  \n",
       "18       1000       3           0   5.020000   6.753656  \n",
       "19       1000       3           0   4.695800   6.753656  \n",
       "20       3000       3           0  41.210000  29.573015  \n",
       "21      13000       3           0   4.380000   6.349485  \n",
       "22       3000       3           0   4.380000   6.837848  \n",
       "23      28925       3           0   4.380000   5.797731  \n",
       "24        755       3           1   4.060000   6.765324  \n",
       "25      15000       3           1   4.060000   6.069651  \n",
       "26      15000       3           0   4.380000   6.447648  \n",
       "27      26174       3           0   4.290000   5.901951  \n",
       "28      28550       3           0   4.639527   5.831109  \n",
       "29       2950       3           1   3.870000   6.658129  \n",
       "..        ...     ...         ...        ...        ...  \n",
       "864      2800       3           1   7.130000   5.629801  \n",
       "865      3040       3           2   7.200000   5.435919  \n",
       "866      1200       3           1   7.130000   5.707938  \n",
       "867     15000       3           2   7.200000   4.851836  \n",
       "868      5000       3           2   7.200000   5.340199  \n",
       "869     10000       8           1   7.130000   5.431674  \n",
       "870      4000       3           1   7.130000   5.571197  \n",
       "871     12000       3           2   7.200000   4.998345  \n",
       "872         1       8           1   7.130000   5.919989  \n",
       "873      5000       7           2   7.200000   5.462996  \n",
       "874     44975       3           0   7.960000   4.204218  \n",
       "875      5000       1           0   7.700000   5.643124  \n",
       "876     10000       3           2   7.600000   5.096018  \n",
       "877     30000       3           1   7.130000   4.301453  \n",
       "878     30000       3           2   7.200000   4.119291  \n",
       "879     20000       1           0   7.700000   4.910580  \n",
       "880     10000       6           2   7.600000   5.188114  \n",
       "881     10000       1           2   7.200000   5.034620  \n",
       "882     15000       1           2   7.200000   4.790438  \n",
       "883     11000       1           2   7.200000   4.985784  \n",
       "884     15000       4           2   1.000000   4.882535  \n",
       "885      2000       4           2   7.600000   5.517407  \n",
       "886     15000       1           2   6.800000   4.790438  \n",
       "887     30000       3           1   7.000000   4.301453  \n",
       "888      5000       3           2   7.600000   5.340199  \n",
       "889      9700       3           2   7.200000   5.110668  \n",
       "890      3000       3           2   7.600000   5.437872  \n",
       "891     10000       1           0   7.700000   5.398943  \n",
       "892     20000       1           2   7.200000   4.546257  \n",
       "893      2000       3           2   7.600000   5.486708  \n",
       "\n",
       "[894 rows x 15 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup prediction\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer\n",
    "linear_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_code</th>\n",
       "      <th>material</th>\n",
       "      <th>box_code</th>\n",
       "      <th>bursting_factor</th>\n",
       "      <th>flute_type</th>\n",
       "      <th>inner_height_mm</th>\n",
       "      <th>height_inch</th>\n",
       "      <th>inner_height</th>\n",
       "      <th>length_inch</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>quantity</th>\n",
       "      <th>status</th>\n",
       "      <th>company_id</th>\n",
       "      <th>per_unit</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>646.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>687.00</td>\n",
       "      <td>7.9</td>\n",
       "      <td>46</td>\n",
       "      <td>795</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.710000</td>\n",
       "      <td>19.284431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>646.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>687.00</td>\n",
       "      <td>7.9</td>\n",
       "      <td>46</td>\n",
       "      <td>12490</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>18.713291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>67.455147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30</td>\n",
       "      <td>2165</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.297081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30</td>\n",
       "      <td>315</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.387428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29</td>\n",
       "      <td>825</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67.229947</td>\n",
       "      <td>67.415344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>14.219876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1998</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>14.140439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>14.127779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>990</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.345800</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>6.784356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>6.692259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.677960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>6.705553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.695800</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>3.1</td>\n",
       "      <td>660.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41.210000</td>\n",
       "      <td>29.573015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>13000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.349485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.837848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36</td>\n",
       "      <td>28925</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>5.797731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>755</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>6.765324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>6.069651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.447648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38</td>\n",
       "      <td>26174</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>5.901951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35</td>\n",
       "      <td>28550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.639527</td>\n",
       "      <td>5.831109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>2950</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>6.658129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.629801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>3040</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.435919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.707938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.851836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.431674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.571197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.998345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.919989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.462996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22</td>\n",
       "      <td>44975</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.960000</td>\n",
       "      <td>4.204218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>5.643124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.096018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>4.301453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.119291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>4.910580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.188114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.034620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.790438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>11000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.985784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.882535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.517407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>4.790438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.301453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>9700</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.110668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.437872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>5.398943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.546257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.486708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sku_code  material  box_code  bursting_factor  flute_type  \\\n",
       "0           1         1        15                5           1   \n",
       "1           1         1        15                5           1   \n",
       "2          21         0        16                0           2   \n",
       "3          22         0         0                0           2   \n",
       "4          22         0         0                0           2   \n",
       "5          21         0        16                0           2   \n",
       "6           5         0         1                1           0   \n",
       "7           5         0         1                1           0   \n",
       "8           5         0         1                1           0   \n",
       "9           5         0         1                1           0   \n",
       "10          5         0         1                1           0   \n",
       "11          5         0         1                1           0   \n",
       "12          5         0         1                1           0   \n",
       "13          4         0         2                1           0   \n",
       "14          4         0         2                1           0   \n",
       "15          4         0         2                1           0   \n",
       "16          4         0         2                1           0   \n",
       "17          4         0         2                1           0   \n",
       "18          4         0         2                1           0   \n",
       "19          4         0         2                1           0   \n",
       "20          3         1         3                4           0   \n",
       "21         13         1         6                3           0   \n",
       "22         13         1         6                3           0   \n",
       "23         13         1         6                3           0   \n",
       "24         13         1         6                3           0   \n",
       "25         13         1         6                3           0   \n",
       "26         13         1         6                3           0   \n",
       "27         13         1         6                3           0   \n",
       "28         13         1         6                3           0   \n",
       "29         13         1         6                3           0   \n",
       "..        ...       ...       ...              ...         ...   \n",
       "864         7         1         7                3           0   \n",
       "865         7         1         7                3           0   \n",
       "866         7         1         7                3           0   \n",
       "867         7         1         7                3           0   \n",
       "868         7         1         7                3           0   \n",
       "869         7         1         7                3           0   \n",
       "870         7         1         7                3           0   \n",
       "871         7         1         7                3           0   \n",
       "872         7         1         7                3           0   \n",
       "873         7         1         7                3           0   \n",
       "874         7         1         7                3           0   \n",
       "875         7         1         7                3           0   \n",
       "876         7         1         7                3           0   \n",
       "877         7         1         7                3           0   \n",
       "878         7         1         7                3           0   \n",
       "879         7         1         7                3           0   \n",
       "880         7         1         7                3           0   \n",
       "881         7         1         7                3           0   \n",
       "882         7         1         7                3           0   \n",
       "883         7         1         7                3           0   \n",
       "884         7         1         7                3           0   \n",
       "885         7         1         7                3           0   \n",
       "886         7         1         7                3           0   \n",
       "887         7         1         7                3           0   \n",
       "888         7         1         7                3           0   \n",
       "889         7         1         7                3           0   \n",
       "890         7         1         7                3           0   \n",
       "891         7         1         7                3           0   \n",
       "892         7         1         7                3           0   \n",
       "893         7         1         7                3           0   \n",
       "\n",
       "     inner_height_mm  height_inch  inner_height  length_inch  updated_at  \\\n",
       "0             646.00          3.9        687.00          7.9          46   \n",
       "1             646.00          3.9        687.00          7.9          46   \n",
       "2             300.00         11.8        730.00         28.7          29   \n",
       "3             300.00         11.8        730.00         28.7          30   \n",
       "4             300.00         11.8        730.00         28.7          30   \n",
       "5             300.00         11.8        730.00         28.7          29   \n",
       "6             101.14          4.1        306.88         12.2          44   \n",
       "7             101.14          4.1        306.88         12.2          44   \n",
       "8             101.14          4.1        306.88         12.2          44   \n",
       "9             101.14          4.1        306.88         12.2          44   \n",
       "10            101.14          4.1        306.88         12.2          44   \n",
       "11            101.14          4.1        306.88         12.2          44   \n",
       "12            101.14          4.1        306.88         12.2          44   \n",
       "13             90.98          3.7        197.66          7.9          45   \n",
       "14             90.98          3.7        197.66          7.9          45   \n",
       "15             90.98          3.7        197.66          7.9          45   \n",
       "16             90.98          3.7        197.66          7.9          45   \n",
       "17             90.98          3.7        197.66          7.9          45   \n",
       "18             90.98          3.7        197.66          7.9          45   \n",
       "19             90.98          3.7        197.66          7.9          45   \n",
       "20             80.00          3.1        660.00         26.0          47   \n",
       "21             90.00          3.0        220.00          8.0          51   \n",
       "22             90.00          3.0        220.00          8.0          51   \n",
       "23             90.00          3.0        220.00          8.0          36   \n",
       "24             90.00          3.0        220.00          8.0          51   \n",
       "25             90.00          3.0        220.00          8.0          51   \n",
       "26             90.00          3.0        220.00          8.0          38   \n",
       "27             90.00          3.0        220.00          8.0          38   \n",
       "28             90.00          3.0        220.00          8.0          35   \n",
       "29             90.00          3.0        220.00          8.0          51   \n",
       "..               ...          ...           ...          ...         ...   \n",
       "864           120.00          4.0        250.00          9.0          52   \n",
       "865           120.00          4.0        250.00          9.0          52   \n",
       "866           120.00          4.0        250.00          9.0          52   \n",
       "867           120.00          4.0        250.00          9.0          52   \n",
       "868           120.00          4.0        250.00          9.0          52   \n",
       "869           120.00          4.0        250.00          9.0          52   \n",
       "870           120.00          4.0        250.00          9.0          52   \n",
       "871           120.00          4.0        250.00          9.0          52   \n",
       "872           120.00          4.0        250.00          9.0          52   \n",
       "873           120.00          4.0        250.00          9.0          52   \n",
       "874           120.00          4.0        250.00          9.0          22   \n",
       "875           120.00          4.0        250.00          9.0          52   \n",
       "876           120.00          4.0        250.00          9.0          52   \n",
       "877           120.00          4.0        250.00          9.0          52   \n",
       "878           120.00          4.0        250.00          9.0          52   \n",
       "879           120.00          4.0        250.00          9.0          52   \n",
       "880           120.00          4.0        250.00          9.0          52   \n",
       "881           120.00          4.0        250.00          9.0          52   \n",
       "882           120.00          4.0        250.00          9.0          52   \n",
       "883           120.00          4.0        250.00          9.0          52   \n",
       "884           120.00          4.0        250.00          9.0          52   \n",
       "885           120.00          4.0        250.00          9.0          52   \n",
       "886           120.00          4.0        250.00          9.0          52   \n",
       "887           120.00          4.0        250.00          9.0          52   \n",
       "888           120.00          4.0        250.00          9.0          52   \n",
       "889           120.00          4.0        250.00          9.0          52   \n",
       "890           120.00          4.0        250.00          9.0          52   \n",
       "891           120.00          4.0        250.00          9.0          52   \n",
       "892           120.00          4.0        250.00          9.0          52   \n",
       "893           120.00          4.0        250.00          9.0          52   \n",
       "\n",
       "     quantity  status  company_id   per_unit  Predicted  \n",
       "0         795       3           0   6.710000  19.284431  \n",
       "1       12490       3           0   7.100000  18.713291  \n",
       "2          10       3           0  63.430000  67.455147  \n",
       "3        2165       3           2  67.000000  62.297081  \n",
       "4         315       3           2  67.000000  62.387428  \n",
       "5         825       3           0  67.229947  67.415344  \n",
       "6        1000       4           0   6.930000  14.219876  \n",
       "7        1998       3           0   7.340000  14.140439  \n",
       "8        1000       1           0   6.930000  14.127779  \n",
       "9        1000       3           0   7.860000  14.189178  \n",
       "10       1000       3           0   7.860000  14.189178  \n",
       "11        990       3           0   7.860000  14.189666  \n",
       "12       1000       3           0   7.345800  14.189178  \n",
       "13       1000       4           0   4.430000   6.784356  \n",
       "14       1000       3           0   5.020000   6.753656  \n",
       "15       1000       1           0   4.430000   6.692259  \n",
       "16       2550       3           0   5.020000   6.677960  \n",
       "17       1985       3           0   4.680000   6.705553  \n",
       "18       1000       3           0   5.020000   6.753656  \n",
       "19       1000       3           0   4.695800   6.753656  \n",
       "20       3000       3           0  41.210000  29.573015  \n",
       "21      13000       3           0   4.380000   6.349485  \n",
       "22       3000       3           0   4.380000   6.837848  \n",
       "23      28925       3           0   4.380000   5.797731  \n",
       "24        755       3           1   4.060000   6.765324  \n",
       "25      15000       3           1   4.060000   6.069651  \n",
       "26      15000       3           0   4.380000   6.447648  \n",
       "27      26174       3           0   4.290000   5.901951  \n",
       "28      28550       3           0   4.639527   5.831109  \n",
       "29       2950       3           1   3.870000   6.658129  \n",
       "..        ...     ...         ...        ...        ...  \n",
       "864      2800       3           1   7.130000   5.629801  \n",
       "865      3040       3           2   7.200000   5.435919  \n",
       "866      1200       3           1   7.130000   5.707938  \n",
       "867     15000       3           2   7.200000   4.851836  \n",
       "868      5000       3           2   7.200000   5.340199  \n",
       "869     10000       8           1   7.130000   5.431674  \n",
       "870      4000       3           1   7.130000   5.571197  \n",
       "871     12000       3           2   7.200000   4.998345  \n",
       "872         1       8           1   7.130000   5.919989  \n",
       "873      5000       7           2   7.200000   5.462996  \n",
       "874     44975       3           0   7.960000   4.204218  \n",
       "875      5000       1           0   7.700000   5.643124  \n",
       "876     10000       3           2   7.600000   5.096018  \n",
       "877     30000       3           1   7.130000   4.301453  \n",
       "878     30000       3           2   7.200000   4.119291  \n",
       "879     20000       1           0   7.700000   4.910580  \n",
       "880     10000       6           2   7.600000   5.188114  \n",
       "881     10000       1           2   7.200000   5.034620  \n",
       "882     15000       1           2   7.200000   4.790438  \n",
       "883     11000       1           2   7.200000   4.985784  \n",
       "884     15000       4           2   1.000000   4.882535  \n",
       "885      2000       4           2   7.600000   5.517407  \n",
       "886     15000       1           2   6.800000   4.790438  \n",
       "887     30000       3           1   7.000000   4.301453  \n",
       "888      5000       3           2   7.600000   5.340199  \n",
       "889      9700       3           2   7.200000   5.110668  \n",
       "890      3000       3           2   7.600000   5.437872  \n",
       "891     10000       1           0   7.700000   5.398943  \n",
       "892     20000       1           2   7.200000   4.546257  \n",
       "893      2000       3           2   7.600000   5.486708  \n",
       "\n",
       "[894 rows x 15 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the first row of data to the predictor\n",
    "result = linear_predictor.predict(modelData[0])\n",
    "print(result)\n",
    "\n",
    "predictions = []\n",
    "for array in modelData:\n",
    "    result = linear_predictor.predict(array)\n",
    "    predictions += [r['score'] for r in result['predictions']]\n",
    "predictions = np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push into our pandas dataframe\n",
    "dataset['Predicted'] = predictions.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_code</th>\n",
       "      <th>material</th>\n",
       "      <th>box_code</th>\n",
       "      <th>bursting_factor</th>\n",
       "      <th>flute_type</th>\n",
       "      <th>inner_height_mm</th>\n",
       "      <th>height_inch</th>\n",
       "      <th>inner_height</th>\n",
       "      <th>length_inch</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>quantity</th>\n",
       "      <th>status</th>\n",
       "      <th>company_id</th>\n",
       "      <th>per_unit</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>646.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>687.00</td>\n",
       "      <td>7.9</td>\n",
       "      <td>46</td>\n",
       "      <td>795</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.710000</td>\n",
       "      <td>19.284431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>646.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>687.00</td>\n",
       "      <td>7.9</td>\n",
       "      <td>46</td>\n",
       "      <td>12490</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>18.713291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>67.455147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30</td>\n",
       "      <td>2165</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.297081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30</td>\n",
       "      <td>315</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.387428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>730.00</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29</td>\n",
       "      <td>825</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67.229947</td>\n",
       "      <td>67.415344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>14.219876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1998</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>14.140439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>14.127779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>990</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>14.189666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>306.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.345800</td>\n",
       "      <td>14.189178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>6.784356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>6.692259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.677960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>6.705553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.98</td>\n",
       "      <td>3.7</td>\n",
       "      <td>197.66</td>\n",
       "      <td>7.9</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.695800</td>\n",
       "      <td>6.753656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>3.1</td>\n",
       "      <td>660.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41.210000</td>\n",
       "      <td>29.573015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>13000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.349485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.837848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36</td>\n",
       "      <td>28925</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>5.797731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>755</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>6.765324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>6.069651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>6.447648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38</td>\n",
       "      <td>26174</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>5.901951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35</td>\n",
       "      <td>28550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.639527</td>\n",
       "      <td>5.831109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51</td>\n",
       "      <td>2950</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>6.658129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.629801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>3040</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.435919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.707938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.851836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.431674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.571197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.998345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>5.919989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.462996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22</td>\n",
       "      <td>44975</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.960000</td>\n",
       "      <td>4.204218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>5.643124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.096018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>4.301453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.119291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>4.910580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.188114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.034620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.790438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>11000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.985784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.882535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.517407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>4.790438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.301453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.340199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>9700</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>5.110668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.437872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>5.398943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.546257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.486708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sku_code  material  box_code  bursting_factor  flute_type  \\\n",
       "0           1         1        15                5           1   \n",
       "1           1         1        15                5           1   \n",
       "2          21         0        16                0           2   \n",
       "3          22         0         0                0           2   \n",
       "4          22         0         0                0           2   \n",
       "5          21         0        16                0           2   \n",
       "6           5         0         1                1           0   \n",
       "7           5         0         1                1           0   \n",
       "8           5         0         1                1           0   \n",
       "9           5         0         1                1           0   \n",
       "10          5         0         1                1           0   \n",
       "11          5         0         1                1           0   \n",
       "12          5         0         1                1           0   \n",
       "13          4         0         2                1           0   \n",
       "14          4         0         2                1           0   \n",
       "15          4         0         2                1           0   \n",
       "16          4         0         2                1           0   \n",
       "17          4         0         2                1           0   \n",
       "18          4         0         2                1           0   \n",
       "19          4         0         2                1           0   \n",
       "20          3         1         3                4           0   \n",
       "21         13         1         6                3           0   \n",
       "22         13         1         6                3           0   \n",
       "23         13         1         6                3           0   \n",
       "24         13         1         6                3           0   \n",
       "25         13         1         6                3           0   \n",
       "26         13         1         6                3           0   \n",
       "27         13         1         6                3           0   \n",
       "28         13         1         6                3           0   \n",
       "29         13         1         6                3           0   \n",
       "..        ...       ...       ...              ...         ...   \n",
       "864         7         1         7                3           0   \n",
       "865         7         1         7                3           0   \n",
       "866         7         1         7                3           0   \n",
       "867         7         1         7                3           0   \n",
       "868         7         1         7                3           0   \n",
       "869         7         1         7                3           0   \n",
       "870         7         1         7                3           0   \n",
       "871         7         1         7                3           0   \n",
       "872         7         1         7                3           0   \n",
       "873         7         1         7                3           0   \n",
       "874         7         1         7                3           0   \n",
       "875         7         1         7                3           0   \n",
       "876         7         1         7                3           0   \n",
       "877         7         1         7                3           0   \n",
       "878         7         1         7                3           0   \n",
       "879         7         1         7                3           0   \n",
       "880         7         1         7                3           0   \n",
       "881         7         1         7                3           0   \n",
       "882         7         1         7                3           0   \n",
       "883         7         1         7                3           0   \n",
       "884         7         1         7                3           0   \n",
       "885         7         1         7                3           0   \n",
       "886         7         1         7                3           0   \n",
       "887         7         1         7                3           0   \n",
       "888         7         1         7                3           0   \n",
       "889         7         1         7                3           0   \n",
       "890         7         1         7                3           0   \n",
       "891         7         1         7                3           0   \n",
       "892         7         1         7                3           0   \n",
       "893         7         1         7                3           0   \n",
       "\n",
       "     inner_height_mm  height_inch  inner_height  length_inch  updated_at  \\\n",
       "0             646.00          3.9        687.00          7.9          46   \n",
       "1             646.00          3.9        687.00          7.9          46   \n",
       "2             300.00         11.8        730.00         28.7          29   \n",
       "3             300.00         11.8        730.00         28.7          30   \n",
       "4             300.00         11.8        730.00         28.7          30   \n",
       "5             300.00         11.8        730.00         28.7          29   \n",
       "6             101.14          4.1        306.88         12.2          44   \n",
       "7             101.14          4.1        306.88         12.2          44   \n",
       "8             101.14          4.1        306.88         12.2          44   \n",
       "9             101.14          4.1        306.88         12.2          44   \n",
       "10            101.14          4.1        306.88         12.2          44   \n",
       "11            101.14          4.1        306.88         12.2          44   \n",
       "12            101.14          4.1        306.88         12.2          44   \n",
       "13             90.98          3.7        197.66          7.9          45   \n",
       "14             90.98          3.7        197.66          7.9          45   \n",
       "15             90.98          3.7        197.66          7.9          45   \n",
       "16             90.98          3.7        197.66          7.9          45   \n",
       "17             90.98          3.7        197.66          7.9          45   \n",
       "18             90.98          3.7        197.66          7.9          45   \n",
       "19             90.98          3.7        197.66          7.9          45   \n",
       "20             80.00          3.1        660.00         26.0          47   \n",
       "21             90.00          3.0        220.00          8.0          51   \n",
       "22             90.00          3.0        220.00          8.0          51   \n",
       "23             90.00          3.0        220.00          8.0          36   \n",
       "24             90.00          3.0        220.00          8.0          51   \n",
       "25             90.00          3.0        220.00          8.0          51   \n",
       "26             90.00          3.0        220.00          8.0          38   \n",
       "27             90.00          3.0        220.00          8.0          38   \n",
       "28             90.00          3.0        220.00          8.0          35   \n",
       "29             90.00          3.0        220.00          8.0          51   \n",
       "..               ...          ...           ...          ...         ...   \n",
       "864           120.00          4.0        250.00          9.0          52   \n",
       "865           120.00          4.0        250.00          9.0          52   \n",
       "866           120.00          4.0        250.00          9.0          52   \n",
       "867           120.00          4.0        250.00          9.0          52   \n",
       "868           120.00          4.0        250.00          9.0          52   \n",
       "869           120.00          4.0        250.00          9.0          52   \n",
       "870           120.00          4.0        250.00          9.0          52   \n",
       "871           120.00          4.0        250.00          9.0          52   \n",
       "872           120.00          4.0        250.00          9.0          52   \n",
       "873           120.00          4.0        250.00          9.0          52   \n",
       "874           120.00          4.0        250.00          9.0          22   \n",
       "875           120.00          4.0        250.00          9.0          52   \n",
       "876           120.00          4.0        250.00          9.0          52   \n",
       "877           120.00          4.0        250.00          9.0          52   \n",
       "878           120.00          4.0        250.00          9.0          52   \n",
       "879           120.00          4.0        250.00          9.0          52   \n",
       "880           120.00          4.0        250.00          9.0          52   \n",
       "881           120.00          4.0        250.00          9.0          52   \n",
       "882           120.00          4.0        250.00          9.0          52   \n",
       "883           120.00          4.0        250.00          9.0          52   \n",
       "884           120.00          4.0        250.00          9.0          52   \n",
       "885           120.00          4.0        250.00          9.0          52   \n",
       "886           120.00          4.0        250.00          9.0          52   \n",
       "887           120.00          4.0        250.00          9.0          52   \n",
       "888           120.00          4.0        250.00          9.0          52   \n",
       "889           120.00          4.0        250.00          9.0          52   \n",
       "890           120.00          4.0        250.00          9.0          52   \n",
       "891           120.00          4.0        250.00          9.0          52   \n",
       "892           120.00          4.0        250.00          9.0          52   \n",
       "893           120.00          4.0        250.00          9.0          52   \n",
       "\n",
       "     quantity  status  company_id   per_unit  Predicted  \n",
       "0         795       3           0   6.710000  19.284431  \n",
       "1       12490       3           0   7.100000  18.713291  \n",
       "2          10       3           0  63.430000  67.455147  \n",
       "3        2165       3           2  67.000000  62.297081  \n",
       "4         315       3           2  67.000000  62.387428  \n",
       "5         825       3           0  67.229947  67.415344  \n",
       "6        1000       4           0   6.930000  14.219876  \n",
       "7        1998       3           0   7.340000  14.140439  \n",
       "8        1000       1           0   6.930000  14.127779  \n",
       "9        1000       3           0   7.860000  14.189178  \n",
       "10       1000       3           0   7.860000  14.189178  \n",
       "11        990       3           0   7.860000  14.189666  \n",
       "12       1000       3           0   7.345800  14.189178  \n",
       "13       1000       4           0   4.430000   6.784356  \n",
       "14       1000       3           0   5.020000   6.753656  \n",
       "15       1000       1           0   4.430000   6.692259  \n",
       "16       2550       3           0   5.020000   6.677960  \n",
       "17       1985       3           0   4.680000   6.705553  \n",
       "18       1000       3           0   5.020000   6.753656  \n",
       "19       1000       3           0   4.695800   6.753656  \n",
       "20       3000       3           0  41.210000  29.573015  \n",
       "21      13000       3           0   4.380000   6.349485  \n",
       "22       3000       3           0   4.380000   6.837848  \n",
       "23      28925       3           0   4.380000   5.797731  \n",
       "24        755       3           1   4.060000   6.765324  \n",
       "25      15000       3           1   4.060000   6.069651  \n",
       "26      15000       3           0   4.380000   6.447648  \n",
       "27      26174       3           0   4.290000   5.901951  \n",
       "28      28550       3           0   4.639527   5.831109  \n",
       "29       2950       3           1   3.870000   6.658129  \n",
       "..        ...     ...         ...        ...        ...  \n",
       "864      2800       3           1   7.130000   5.629801  \n",
       "865      3040       3           2   7.200000   5.435919  \n",
       "866      1200       3           1   7.130000   5.707938  \n",
       "867     15000       3           2   7.200000   4.851836  \n",
       "868      5000       3           2   7.200000   5.340199  \n",
       "869     10000       8           1   7.130000   5.431674  \n",
       "870      4000       3           1   7.130000   5.571197  \n",
       "871     12000       3           2   7.200000   4.998345  \n",
       "872         1       8           1   7.130000   5.919989  \n",
       "873      5000       7           2   7.200000   5.462996  \n",
       "874     44975       3           0   7.960000   4.204218  \n",
       "875      5000       1           0   7.700000   5.643124  \n",
       "876     10000       3           2   7.600000   5.096018  \n",
       "877     30000       3           1   7.130000   4.301453  \n",
       "878     30000       3           2   7.200000   4.119291  \n",
       "879     20000       1           0   7.700000   4.910580  \n",
       "880     10000       6           2   7.600000   5.188114  \n",
       "881     10000       1           2   7.200000   5.034620  \n",
       "882     15000       1           2   7.200000   4.790438  \n",
       "883     11000       1           2   7.200000   4.985784  \n",
       "884     15000       4           2   1.000000   4.882535  \n",
       "885      2000       4           2   7.600000   5.517407  \n",
       "886     15000       1           2   6.800000   4.790438  \n",
       "887     30000       3           1   7.000000   4.301453  \n",
       "888      5000       3           2   7.600000   5.340199  \n",
       "889      9700       3           2   7.200000   5.110668  \n",
       "890      3000       3           2   7.600000   5.437872  \n",
       "891     10000       1           0   7.700000   5.398943  \n",
       "892     20000       1           2   7.200000   4.546257  \n",
       "893      2000       3           2   7.600000   5.486708  \n",
       "\n",
       "[894 rows x 15 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
